# RÃ¨gles et Guide Podman pour l'IA GÃ©nÃ©rative

## âš™ï¸ CONTEXTE POUR LE CHAT (Ã€ METTRE Ã€ JOUR)
**Contexte / Contraintes**
- **OS** : openSUSE Tumbleweed
- **Carte graphique** : NVIDIA GTX 3070 (driver 580.82.07), CUDA 13.0 (hÃ´te)
- **Outils** : Podman (mode **rootless**), git
- **Langages** : bash, Python 3.1*
- **Securite** : Selinux enforced
- **disque externe**
  - **Type de disque** : HDD (disque dur mÃ©canique, modÃ¨le 2019).
  - **SystÃ¨me de fichiers** : EXT4.
  - **Taille** : 4 To, exclusivement dÃ©diÃ© Ã  Podman.
  - **ontage manuel** : sur UUID.
  - **Utilisation** : Exclusivement dÃ©diÃ© Ã  Podman.

**Objectifs Principaux**
- Isoler les applications d'IA gÃ©nÃ©rative (SD, ComfyUI, etc.) dans des **pods rÃ©utilisables**.
- Utiliser une **version fixe de CUDA (12.4)** pour Ã©viter les incompatibilitÃ©s.
- Stocker **images et pods sur un disque externe amovible dÃ©diÃ©**, pour :
  - Ã‰viter toute pollution des autres disques.
  - BÃ©nÃ©ficier dâ€™un espace dÃ©diÃ© et modulable.
  - Pouvoir monter/dÃ©monter le disque **sans impact sur le systÃ¨me hÃ´te**.

**Fonctionnement de base**

OÃ¹ sont les Pods et les Conteneurs ?
### Stockage des DonnÃ©es par Podman
Podman stocke tous les conteneurs, pods, images et volumes dans un dossier centralisÃ© :

Chemin par dÃ©faut : ~/.local/share/containers/
Structure interne :

libpod/ : Contient les mÃ©tadonnÃ©es des conteneurs, pods, images et volumes.
overlay/ : Contient les couches de stockage des conteneurs (systÃ¨me de fichiers en couches).
volumes/ : Contient les volumes nommÃ©s.

### Ton Arborescence Externe (/mnt/podman/)

Dans ton cas, tu as redirigÃ© le stockage de Podman vers ton disque externe via des liens symboliques. Voici comment cela fonctionne :

Chaque dossier pod_*/storage/ (ex: pod_sd/storage/, pod_comfyui/storage/) est liÃ© Ã  ~/.local/share/containers/storage via un lien symbolique.
En rÃ©alitÃ©, Podman utilise toujours ~/.local/share/containers/storage comme point de montage, mais grÃ¢ce Ã  tes liens symboliques, les donnÃ©es sont stockÃ©es sur /mnt/podman/pod_*/storage/.

- OÃ¹ sont les Pods et Conteneurs Physiquement ?

Pods : Les mÃ©tadonnÃ©es des pods sont stockÃ©es dans libpod/ (ex: ~/.local/share/containers/storage/libpod/).
Conteneurs : Chaque conteneur est un sous-dossier dans libpod/containers/ (ex: ~/.local/share/containers/storage/libpod/containers/<container_id>/).
Images : Les images sont stockÃ©es dans libpod/images/ (ex: ~/.local/share/containers/storage/libpod/images/).

### Exemple Concret avec pod_sd et pod_comfyui
a. Structure Logique (Podman)

Pod sd_pod :

Conteneur 1 : sd_app (Stable Diffusion)
Conteneur 2 : sd_web (Interface web)

Pod comfyui_pod :

Conteneur 1 : comfyui_app (ComfyUI)
Conteneur 2 : comfyui_web (Interface web)

b. Structure Physique (Disque Externe)

Pour pod_sd :

/mnt/podman/pod_sd/storage/libpod/containers/ : Contient les mÃ©tadonnÃ©es des conteneurs sd_app et sd_web.
/mnt/podman/pod_sd/storage/libpod/pods/ : Contient les mÃ©tadonnÃ©es du pod sd_pod.

Pour pod_comfyui :

/mnt/podman/pod_comfyui/storage/libpod/containers/ : Contient les mÃ©tadonnÃ©es des conteneurs comfyui_app et comfyui_web.
/mnt/podman/pod_comfyui/storage/libpod/pods/ : Contient les mÃ©tadonnÃ©es du pod comfyui_pod.

### RÃ©utilisation du Conteneur NVIDIA
a. Chaque Pod est IndÃ©pendant

Si tu crÃ©es un pod pour SD (sd_pod) et un pod pour ComfyUI (comfyui_pod), chaque pod peut contenir son propre conteneur utilisant les ressources NVIDIA.
Exemple :

sd_pod : Conteneur sd_app avec --gpus all.
comfyui_pod : Conteneur comfyui_app avec --gpus all.

b. Ressources PartagÃ©es ou Non ?

Non partagÃ©es : Chaque pod a son propre espace de noms et ses propres ressources. Les conteneurs dans diffÃ©rents pods ne partagent pas les ressources GPU ou CPU par dÃ©faut.
PartagÃ©es : Si tu veux que deux conteneurs partagent les mÃªmes ressources GPU, ils doivent Ãªtre dans le mÃªme pod.


---

## 1. Contraintes et Choix de Base

### 1.1 Stockage sur Disque Externe Amovible
- **Organisation** :
  - Un rÃ©pertoire dÃ©diÃ© sur le disque externe pour les images/pods (ex : `/mnt/podman`).
  - Configuration de Podman pour utiliser ce rÃ©pertoire comme stockage par dÃ©faut.
- **Avantages** :
  - Espace illimitÃ© (selon la taille du disque).
  - PossibilitÃ© de dÃ©monter le disque quand il nâ€™est pas utilisÃ©.
- **Script de Montage** :
  ```bash
  #!/bin/bash
  # Monter le disque (adapter l'UUID)
  sudo mount /dev/disk/by-uuid/TON_UUID_DU_DISQUE /mnt/podman
  # CrÃ©er le lien symbolique
  ln -sf /mnt/podman/podman_data/storage ~/.local/share/containers/storage
  echo "Disque montÃ© et Podman prÃªt ! ğŸ±
  ```
- **Permissions** :
  ```bash
  sudo chown -R \$USER:\$USER /mnt/podman
  ```
- #### ğŸ—ƒï¸ Organisation du Disque Externe
  - #### ğŸ“Structure RecommandÃ©e 
```
/mnt/podman/
â”œâ”€â”€ pod_sd/          # Lien symbolique vers ~/.local/share/containers/
â”‚   â””â”€â”€ storage/         # Contient images, conteneurs et mÃ©tadonnÃ©es Podman
â”‚       â”œâ”€â”€ libpod/      # DonnÃ©es internes (conteneurs, images, volumes)
â”‚       â”œâ”€â”€ overlay/      # Couches overlay
â”‚       â””â”€â”€ volumes/      # Volumes nommÃ©s (optionnel)
â”‚
â”œâ”€â”€ pod_comfyui/          # Lien symbolique vers ~/.local/share/containers/
â”‚   â””â”€â”€ storage/         # Contient images, conteneurs et mÃ©tadonnÃ©es Podman
â”‚       â”œâ”€â”€ libpod/      # DonnÃ©es internes (conteneurs, images, volumes)
â”‚       â”œâ”€â”€ overlay/      # Couches overlay
â”‚       â””â”€â”€ volumes/      # Volumes nommÃ©s (optionnel)
â”‚
â”œâ”€â”€ pod_cdrage/          # Lien symbolique vers ~/.local/share/containers/
â”‚   â””â”€â”€ storage/         # Contient images, conteneurs et mÃ©tadonnÃ©es Podman
â”‚       â”œâ”€â”€ libpod/      # DonnÃ©es internes (conteneurs, images, volumes)
â”‚       â”œâ”€â”€ overlay/      # Couches overlay
â”‚       â””â”€â”€ volumes/      # Volumes nommÃ©s (optionnel)
â”‚
â”œâ”€â”€ pod_kohya_ss/          # Lien symbolique vers ~/.local/share/containers/
â”‚   â””â”€â”€ storage/         # Contient images, conteneurs et mÃ©tadonnÃ©es Podman
â”‚       â”œâ”€â”€ libpod/      # DonnÃ©es internes (conteneurs, images, volumes)
â”‚       â”œâ”€â”€ overlay/      # Couches overlay
â”‚       â””â”€â”€ volumes/      # Volumes nommÃ©s (optionnel)
â”‚
â”œâ”€â”€ pod_jupyter_lab/          # Lien symbolique vers ~/.local/share/containers/
â”‚   â””â”€â”€ storage/         # Contient images, conteneurs et mÃ©tadonnÃ©es Podman
â”‚       â”œâ”€â”€ libpod/      # DonnÃ©es internes (conteneurs, images, volumes)
â”‚       â”œâ”€â”€ overlay/      # Couches overlay
â”‚       â””â”€â”€ volumes/      # Volumes nommÃ©s (optionnel)
â”‚
â”œâ”€â”€ pod_base/          # Lien symbolique vers ~/.local/share/containers/
â”‚   â””â”€â”€ storage/         # Contient images, conteneurs et mÃ©tadonnÃ©es Podman
â”‚       â”œâ”€â”€ libpod/      # DonnÃ©es internes (conteneurs, images, volumes)
â”‚       â”œâ”€â”€ overlay/      # Couches overlay
â”‚       â””â”€â”€ volumes/      # Volumes nommÃ©s (optionnel)
â”‚
â”œâ”€â”€ pod_xxx/          # Lien symbolique vers ~/.local/share/containers/
â”‚   â””â”€â”€ storage/         # Contient images, conteneurs et mÃ©tadonnÃ©es Podman
â”‚       â”œâ”€â”€ libpod/      # DonnÃ©es internes (conteneurs, images, volumes)
â”‚       â”œâ”€â”€ overlay/      # Couches overlay
â”‚       â””â”€â”€ volumes/      # Volumes nommÃ©s (optionnel)
â”‚
â”œâ”€â”€ shared_volumes/      # Dossiers partagÃ©s entre pods (images, modÃ¨les, workflows)
â”‚   â”œâ”€â”€ images/          # Images gÃ©nÃ©rÃ©es par SD/ComfyUI/autres
â”‚   â”‚   â”œâ”€â”€ stable-diffusion/  # Outputs de Stable Diffusion
â”‚   â”‚   â”œâ”€â”€ comfyui/          # Outputs de ComfyUI
â”‚   â”‚   â””â”€â”€ ...              # Autres outils
â”‚   â”œâ”€â”€ models/          # ModÃ¨les partagÃ©s (checkpoints, LoRAs)
â”‚   â””â”€â”€ workflows/       # Workflows ComfyUI rÃ©utilisables
â”‚
â”œâ”€â”€ build/
â”‚   â”œâ”€â”€ storage/          # RÃ©pertoire pour stocker les images construites
â”‚   â”‚   â”œâ”€â”€ <nom_image_1> # RÃ©sultat du build
â”‚   â”‚   â”œâ”€â”€ <nom_image_2> # RÃ©sultat du build
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ pod_sd/           # RÃ©pertoire pour construire l'image de Stable Diffusion
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ scripts/
â”‚   â”œâ”€â”€ pod_base/         # RÃ©pertoire pour construire une image de base
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ scripts/
â”‚   â””â”€â”€ xxx/              # Autres projets
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â””â”€â”€ scripts/
â”‚
â””â”€â”€ README.md            # Instructions pour le montage et l'utilisation```
```

  - ğŸ“**DÃ©finition des Dossiers ProposÃ©s**
    -  **Lien Symbolique pour Podman (`podman_data/`)**
        - **Objectif** : Rediriger `~/.local/share/containers/storage` vers `/mnt/podman_external/podman_data/storage` pour stocker **images, conteneurs et mÃ©tadonnÃ©es** sur le disque amovible.
        - **Avantage** : Pas de modification de l'installation Podman existante.
         - **InconvÃ©nient** : Le disque doit Ãªtre montÃ© avant d'utiliser Podman.
    - **pod_xxx/** :Contient les donnÃ©es internes de Podman (images, conteneurs, mÃ©tadonnÃ©es).RedirigÃ© via un lien symbolique vers ~/.local/share/containers/storage.
    - **libpod/** : Stocke les couches des images, les mÃ©tadonnÃ©es des conteneurs, et les fichiers de configuration.
    - **overlay/** : Contient les couches en Ã©criture des conteneurs (modifications apportÃ©es aux images de base).
    - **volumes/** : UtilisÃ© uniquement si tu crÃ©es des volumes nommÃ©s avec podman volume create. Optionnel dans ton cas, car tu utilises shared_volumes/.
    - **shared_volumes/** :Dossiers partagÃ©s entre pods pour les images gÃ©nÃ©rÃ©es, modÃ¨les, et workflows.
    - **images/** : Centralise les outputs des outils (SD, ComfyUI) pour faciliter les opÃ©rations comme img2img.
    - **models/** : Stocke les modÃ¨les partagÃ©s (checkpoints, LoRAs).
    - **workflows/** : Contient les workflows rÃ©utilisables pour ComfyUI
      - Exemple de Workflow :
        - Stable Diffusion gÃ©nÃ¨re des images dans shared_volumes/images/stable-diffusion/.
        - ComfyUI monte shared_volumes/images/ et utilise les images de SD pour du img2img.
        - RÃ©sultat : Pas de duplication, flux de travail fluide.
    - **Logs** :Les logs restent stockÃ©s dans chaque pod ou conteneur, et ne sont pas centralisÃ©s dans shared_volumes/.
  - ğŸ“**Exemple Concret**
    - Tu lances un conteneur Stable Diffusion :
      ```bash 
      podman run -d --name sd-pod -v /mnt/podman/shared_volumes/images/sd:/outputs nvidia/cuda:12.4.0
      ```
      - Image de base : libpod/images/ (couches de nvidia/cuda:12.4.0).
      - MÃ©tadonnÃ©es : libpod/containers/<ID_SD_POD>/.
      - DonnÃ©es en Ã©criture : overlay-containers/<ID_SD_POD>/ (si le conteneur Ã©crit en dehors de /outputs).
      - Images gÃ©nÃ©rÃ©es : shared_volumes/images/sd/ (montÃ© via -v).
    - Tu arrÃªtes le conteneur :Les fichiers dans overlay-containers/<ID_SD_POD>/ persistent (sauf si tu fais podman rm sd-pod).
Les images gÃ©nÃ©rÃ©es restent dans shared_volumes/images/sd/.

### 1.2 Configuration du Disque Externe (WD My Passport 4 To)
- **Type de disque** : HDD (disque dur mÃ©canique, modÃ¨le 2019).
- **SystÃ¨me de fichiers** : EXT4 (Linux).
- **Taille** : 4 To, exclusivement dÃ©diÃ© Ã  Podman.
- **UUID** : `003A24B23A24A71E`.
- **Point de montage** : `/mnt/podman` (fixe, pour Ã©viter les conflits avec `/run/media/`).
  - **ProblÃ¨me** : Montage automatique par `udev` dans `/run/media/dcrazyboy/my\ passport/`, ce qui peut entrer en conflit avec un autre disque similaire.
  - **Solution** : Utiliser un **point de montage fixe** (`/mnt/podman`) et dÃ©sactiver le montage automatique par `udev`.
- **Utilisation** : Exclusivement dÃ©diÃ© Ã  Podman.
- **Utilisation avec NTFS** 
  - **Avantages** :
    - Compatible avec Windows et Linux.
    - Pas besoin de reformater.
  - **InconvÃ©nients** :
    - Performances lÃ©gÃ¨rement infÃ©rieures Ã  ext4 sous Linux.
    - Pas de support natif pour les permissions Linux (dâ€™oÃ¹ lâ€™importance des options uid, gid, dmask, fmask dans /etc/fstab).
  - **DÃ©cision**
    - Reformatage en ext4 

voir section "Configuration Technique" -> "PrÃ©paration du Disque Externe"

### 1.3 Briques Ã  empiler vs. images toutes faites ?
#### 1.3.1 Images toutes faites (ex : cdrage/ai-image-generation-aio-podman)

- **Avantages** :
  - PrÃªtes Ã  lâ€™emploi : Pas besoin de configurer manuellement les dÃ©pendances (CUDA, Python, extensions).
  - OptimisÃ©es : Souvent allÃ©gÃ©es (ex : suppression des modÃ¨les par dÃ©faut comme SDXL pour gagner de la place).
  - IntÃ©gration facile : Partage des modÃ¨les/LoRAs entre outils (ex : Stable Diffusion â†’ ComfyUI).
  - Maintenance simplifiÃ©e : Mises Ã  jour gÃ©rÃ©es par le mainteneur de lâ€™image.
- **InconvÃ©nients** :
  - Moins flexibles : Difficile de modifier la configuration de base (ex : changer de version de CUDA).
  - Taille : Certaines images peuvent Ãªtre lourdes (mÃªme allÃ©gÃ©es).
  - DÃ©pendance au mainteneur : Si lâ€™image nâ€™est plus mise Ã  jour, tu devras migrer.

#### 1.3.2 Briques Ã  empiler (ex : partir de nvidia/cuda:12.4.0 et ajouter les outils)

- **Avantages** :
  - ContrÃ´le total : Tu choisis chaque composant (version de Python, extensions, etc.).
  - Personnalisation : AdaptÃ© pour des besoins spÃ©cifiques (ex : ajouter un outil rare).
  - Apprentissage : Meilleure comprÃ©hension du fonctionnement des conteneurs.
- **InconvÃ©nients** :
  - ComplexitÃ© : Configuration manuelle des dÃ©pendances (risque dâ€™erreurs).
  - Maintenance : Tu dois gÃ©rer les mises Ã  jour toi-mÃªme.
  - Temps : Plus long Ã  mettre en place.

#### 1.3.3 Images Podman pour SD/ComfyUI (cdrage et autres)

- **cdrage/ai-image-generation-aio-podman**
  - Contenu :
Stable Diffusion WebUI (avec ControlNet, After Detailer, Dreambooth, etc.).
ComfyUI (avec synchronisation des modÃ¨les/LoRAs entre les outils).
Kohya_ss (pour lâ€™entraÃ®nement de modÃ¨les).
Jupyter Lab pour uploader/modifier des fichiers.
  - Avantages :
Tout-en-un : IdÃ©al pour dÃ©marrer rapidement.
Synchronisation des modÃ¨les : TÃ©lÃ©charge un modÃ¨le dans SD, il apparaÃ®t dans ComfyUI.
AllÃ©gÃ© : ModÃ¨les par dÃ©faut supprimÃ©s (ex : SDXL).
  - InconvÃ©nients :
Linux uniquement : Ne fonctionne pas sur macOS/Windows via Podman Machine.
Personnalisation limitÃ©e : Difficile dâ€™ajouter des outils non prÃ©vus.

- **ai-dock/comfyui** :
SpÃ©cialisÃ© pour ComfyUI avec support NVIDIA GPU et gestion des UID/GID.
  - Avantages : 
LÃ©ger, configurable, adaptÃ© aux environnements cloud/locaux.
  - InconvÃ©nients : 
Moins dâ€™outils intÃ©grÃ©s que cdrage.

- **mmartial/ComfyUI-Nvidia-Docker** :
Pour NVIDIA GPU avec gestion des permissions utilisateur.
  - Avantages : 
SÃ©paration claire entre donnÃ©es utilisateur et runtime (dossier basedir).
  - InconvÃ©nients : 
Configuration plus complexe pour les dÃ©butants.

- **YanWenKun/ComfyUI-Docker** :
Simple pour les dÃ©butants (inclut ComfyUI-Manager et le modÃ¨le Photon SD1.5).
  - Avantages : 
Facile Ã  dÃ©ployer, mÃªme en WSL2.
  - InconvÃ©nients : 
Pas recommandÃ© pour Podman rootless.

#### 1.3.4 RÃ©sumÃ© des Avantages/InconvÃ©nients

|CritÃ¨re        |Images toutes faites|Briques Ã  empiler
|:--|:--:|:--:| 
|FacilitÃ©|â­â­â­â­â­ (ex : cdrage)|â­â­ (complexe)|
|FlexibilitÃ©|â­â­ (limitÃ©e)|â­â­â­â­â­ (totale)|
|Maintenance|â­â­â­â­ (gÃ©rÃ©e par le mainteneur)|â­ (Ã  toi de tout gÃ©rer)|
|Apprentissage|â­ (peu de contrÃ´le)|â­â­â­â­â­ (meilleure comprÃ©hension)|
|Performance|â­â­â­ (optimisÃ©e)|â­â­â­â­ (si bien configurÃ©)|

#### 1.3.5 CompatibilitÃ© avec la structure d'installation prÃ©vue
Lâ€™image cdrage/ai-image-generation-aio-podman est trÃ¨s proche la rÃ©flexion actuelle, mais elle nÃ©cessite quelques adaptations mineures pour sâ€™intÃ©grer parfaitement au schÃ©ma dâ€™organisation du disque externe.
A noter :
- **CompatibilitÃ© avec organisation prÃ©vue**
  - Points communs :
  - Partage des modÃ¨les/LoRAs : 
  Lâ€™image cdrage synchronise automatiquement les modÃ¨les entre Stable Diffusion et ComfyUI, ce qui correspond Ã  ton objectif de partage via shared_volumes/models/.
  - Utilisation de volumes : 
  Elle est conÃ§ue pour monter des dossiers locaux (comme ton /mnt/podman/shared_volumes/).
  - Mode rootless : 
  Fonctionne en mode rootless (comme ta configuration Podman).
  - PAs besoin de changer de pod pour passe de SD Ã  ComfyUI
  - Montage des Volumes
    - ProblÃ¨me : Lâ€™image cdrage sâ€™attend Ã  un dossier /workspace pour stocker les donnÃ©es persistantes (modÃ¨les, images gÃ©nÃ©rÃ©es, etc.).
    - Solution : Monte tes dossiers shared_volumes/ dans /workspace Ã  lâ€™intÃ©rieur du conteneur
Lien Symbolique pour Podman
  - Le lien symbolique (/mnt/podman/podman_data/storage) reste inchangÃ©.
  - Lâ€™image cdrage nâ€™interfÃ¨re pas avec la configuration de Podman elle-mÃªme (elle utilise les volumes montÃ©s, pas le stockage interne de Podman).
  - Pas besoin de modifier ta configuration prÃ©vue de Podman.

- **Points d'attention**
  - Ports : 
Lâ€™image cdrage expose plusieurs ports (ex : 3000 pour SD, 8888 pour Jupyter Lab). Assure-toi quâ€™ils ne sont pas en conflit avec dâ€™autres services.
  - ModÃ¨les par dÃ©faut : 
Certains modÃ¨les (comme SDXL) sont supprimÃ©s pour gagner de la place. Tu devras les tÃ©lÃ©charger manuellement dans shared_volumes/models/.
  - Extensions : 
Lâ€™image inclut des plugins pour Stable Diffusion (ControlNet, After Detailer, etc.). VÃ©rifie quâ€™ils correspondent Ã  tes besoins.

- **Avantages de cette IntÃ©gration**
  - Pas de duplication : 
  Les donnÃ©es restent sur le disque externe, dans shared_volumes/.
  - CompatibilitÃ© totale : 
  Lâ€™image cdrage utilise les chemins existants.
  - FlexibilitÃ© : 
  DÃ©montage du disque sans perdre des donnÃ©es (elles restent dans shared_volumes/).

#### 1.3.6 Configuration prÃ©vue vs. cdrage

- **Configuration prÃ©vue** :
  - Un pod Podman pour Stable Diffusion et un autre pour ComfyUI, avec des dossiers partagÃ©s (shared_volumes/).
  - InconvÃ©nient : On dois basculer entre les pods pour utiliser SD ou ComfyUI.
  - Avantage : ContrÃ´le total sur chaque outil, mais moins pratique pour un workflow fluide.
- **cdrage/ai-image-generation-aio-podman** :
  - Tout-en-un : 
  Stable Diffusion et ComfyUI (et dâ€™autres outils) dans le mÃªme conteneur.
  - Pas besoin de changer de pod : 
  Tu peux passer de SD Ã  ComfyUI en un clic (via les ports exposÃ©s).
  - Synchronisation automatique : 
  Les modÃ¨les/LoRAs/Images sont partagÃ©s entre les outils sans configuration supplÃ©mentaire.
  - Outils intÃ©grÃ©s : 
  Inclut Kohya_ss (pour crÃ©er des LoRAs/modÃ¨les), Dreambooth, et dâ€™autres extensions.

**EN RESUME**

|CritÃ¨re|Configuration prÃ©vue|cdrage/aio-podman{}
| :--- | :---: | :---: |
|Nombre de pods|2 (SD + ComfyUI)|1 (tout-en-un)[]
|Basculer entre SD/ComfyUI|Oui (changer de pod)|Non (accÃ¨s via diffÃ©rents ports)|
|Partage des modÃ¨les|Manuel (via shared_volumes/)|Automatique (synchronisÃ©)|
|Outils intÃ©grÃ©s|Aucun (Ã  ajouter manuellement)|Kohya_ss, Dreambooth, Jupyter Lab, etc.|
|CrÃ©ation de LoRAs|Non|Oui (via Kohya_ss)
|Interface unifiÃ©e|Non|Oui (Jupyter Lab pour tout gÃ©rer)

#### 1.3.6 PossibilitÃ© solution hybrudre Configuration prevue + cdrage

oui, la structure de disque necessaire pour cdrage est la suivante
```
/mnt/podman/
â”œâ”€â”€ podman_data/          # Lien symbolique vers ~/.local/share/containers/ (inchangÃ©)
â”‚   â””â”€â”€ storage/          # Stockage interne de Podman (images, conteneurs, mÃ©tadonnÃ©es)
â”‚
â”œâ”€â”€ shared_volumes/       # MontÃ© dans /workspace/ Ã  l'intÃ©rieur du conteneur
â”‚   â”œâ”€â”€ images/           # â†’ /workspace/images (images gÃ©nÃ©rÃ©es)
â”‚   â”œâ”€â”€ models/           # â†’ /workspace/models (modÃ¨les/LoRAs)
â”‚   â””â”€â”€ workflows/        # â†’ /workspace/workflows (workflows ComfyUI)
â”‚
â””â”€â”€ README.md
```

Cela implique uen modification du plan prÃ©vu
```
/mnt/podman/
â”œâ”€â”€ shared_volumes/
â”‚   â”œâ”€â”€ images/          # Images gÃ©nÃ©rÃ©es (SD + ComfyUI)
â”‚   â”œâ”€â”€ models/          # ModÃ¨les/LoRAs (SD + ComfyUI + Kohya_ss)
â”‚   â”œâ”€â”€ workflows/       # Workflows ComfyUI
â”‚   â””â”€â”€ training_data/   # Datasets pour Kohya_ss
â”‚
â”œâ”€â”€ pod_sd/              # Pod Stable Diffusion
â”œâ”€â”€ pod_comfyui/         # Pod ComfyUI
â””â”€â”€ pod_kohya_ss/        # Pod Kohya_ss (activÃ© ponctuellement)
```



#### 1.3.7 dÃ©finition complÃ©mentaires des outls

- **Kohya_ss et CrÃ©ation de LoRAs/ModÃ¨les**
  - Kohya_ss est un outil intÃ©grÃ© dans lâ€™image cdrage pour :
  - EntraÃ®ner des LoRAs (Low-Rank Adaptations) Ã  partir de tes propres datasets.
  - CrÃ©er des modÃ¨les personnalisÃ©s (fine-tuning de Stable Diffusion).
  - CompatibilitÃ© avec le PC :
    - Oui, Ã§a devrait tourner si tu as :
    - Une carte NVIDIA GTX 3070 (comme tu lâ€™as mentionnÃ©).
    - Assez de VRAM (au moins 8 Go pour entraÃ®ner des LoRAs lÃ©gers).
  - Podman avec support GPU (dÃ©jÃ  configurÃ© chez toi).
- **Jupyter Lab : Ã€ quoi Ã§a sert ?**
  - Jupyter Lab est un environnement interactif (comme un notebook) intÃ©grÃ© Ã  lâ€™image cdrage. Il permet de :
  - Uploader/tÃ©lÃ©charger des fichiers (modÃ¨les, images, datasets) via une interface web.
  - Ã‰crire du code Python pour automatiser des tÃ¢ches (ex : prÃ©-traitement dâ€™images avant entraÃ®nement).
  - Visualiser et organiser tes donnÃ©es (ex : parcourir les images gÃ©nÃ©rÃ©es).
  - Lancer des scripts pour Kohya_ss ou dâ€™autres outils sans quitter ton navigateur.

#### 1.3.7.1 Outils Ã  Ajouter dans les Pods SD et ComfyUI
(Ã€ installer dans les deux pods pour une expÃ©rience complÃ¨te et cohÃ©rente)
- **Extensions pour Stable Diffusion**
  - ControlNet :
    - Pourquoi ? :
  Permet un contrÃ´le prÃ©cis sur la gÃ©nÃ©ration dâ€™images (poses, compositions).
    - Installation : 
  Ajoute lâ€™extension via le gestionnaire dâ€™extensions de SD ou en montant un dossier extensions/ dans ton pod.
    - Dossier partagÃ© : 
  shared_volumes/models/ControlNet/ (pour les modÃ¨les).
  - After Detailer :
    - Pourquoi ? : 
  AmÃ©liore les dÃ©tails des images aprÃ¨s la gÃ©nÃ©ration initiale.
    - Installation : 
  Extension disponible dans le gestionnaire de SD.
  - Dreambooth :
    - Pourquoi ? : 
  Pour entraÃ®ner des modÃ¨les personnalisÃ©s (ex : ton visage, un style artistique).
    - Installation : 
  Extension ou script Python dans le pod SD.
  - Deforum :
    - Pourquoi ? :
  GÃ©nÃ©ration de vidÃ©os Ã  partir dâ€™images (animation).
    - Installation : 
  Script Python ou extension dans le pod SD.
- **Extensions pour ComfyUI**
  - ComfyUI-Manager :
    - Pourquoi ? : 
  Gestion centralisÃ©e des extensions et modÃ¨les pour ComfyUI.
    - Installation : 
  Ã€ ajouter via Git dans le pod ComfyUI.
    - Dossier partagÃ© : 
  shared_volumes/models/ et shared_volumes/workflows/.
  - ControlNet pour ComfyUI :
  - Pourquoi ? : 
  MÃªme utilitÃ© que dans SD, mais adaptÃ© Ã  lâ€™interface de ComfyUI.
  - Installation : 
  Via ComfyUI-Manager.
- IP-Adapter :
  - Pourquoi ? : 
  GÃ©nÃ©ration dâ€™images guidÃ©e par une image de rÃ©fÃ©rence (style transfer).
  - Installation : E
  xtension pour ComfyUI.

#### 1.3.7.2 Outils SpÃ©cifiques Ã  SÃ©parer (Pods IndÃ©pendants)
(Ã€ installer dans des pods dÃ©diÃ©s, car moins frÃ©quemment utilisÃ©s)
a. Kohya_ss
- Pourquoi sÃ©parer ? : UtilisÃ© uniquement pour lâ€™entraÃ®nement de LoRAs/modÃ¨les (ressource intensive, besoin ponctuel).
- Pod dÃ©diÃ© :
  Image de base : python:3.10 + CUDA 12.4.
- Installation :
  git clone https://github.com/bmaltais/kohya_ss
  pip install -r requirements.txt
- Montage des dossiers :
-v /mnt/podman/shared_volumes/models:/kohya_ss/models \
-v /mnt/podman/shared_volumes/training_data:/kohya_ss/training_data
- Utilisation : 
Lance le pod uniquement quand tu as besoin dâ€™entraÃ®ner un LoRA.

b. Jupyter Lab
- Pourquoi sÃ©parer ? : 
Utile pour le dÃ©veloppement/automatisation, mais pas nÃ©cessaire en permanence.
- Pod dÃ©diÃ© :
  - Image de base : jupyter/base-notebook + CUDA 12.4.
  - Montage des dossiers :
-v /mnt/podman/shared_volumes:/workspace
  - Utilisation : 
Pour uploader des fichiers, Ã©crire des scripts, ou automatiser des tÃ¢ches entre SD/ComfyUI.

**Organisation des Dossiers PartagÃ©s**
Voir **ğŸ“Structure RecommandÃ©e** pour la version finale 

### 1.4 Rootless (Obligatoire)
- **Pourquoi ?**
  - SÃ©curitÃ© : Pas besoin de droits root pour gÃ©rer les pods/images.
  - FlexibilitÃ© : Permet de monter/dÃ©monter le disque externe sans contraintes.
  - Isolation : Tout est contenu sur le disque dÃ©diÃ©, pas de risque de pollution.
- **Comment ?**
  - Podman sera configurÃ© en mode **rootless** (voir section "Configuration Technique").
  - Le disque externe sera montÃ© avec des permissions adaptÃ©es pour lâ€™utilisateur courant.

### 1.5 Version de CUDA (FixÃ©e Ã  12.4)
- **Justification** :
  - CUDA 13.0 peut poser des problÃ¨mes de compatibilitÃ© (ex : SD 1.x).
  - CUDA 12.4 est stable et compatible avec le driver 580.82.07.
- **ImplÃ©mentation** :
  - Les images des pods utiliseront CUDA 12.4 (via des conteneurs NVIDIA appropriÃ©s).
 
### 1.6 AccÃ©lÃ©ration GPU
- **PrÃ©requis** :
  - Installer `nvidia-container-toolkit` sur lâ€™hÃ´te :
    ```bash
    sudo zypper install nvidia-container-toolkit
    sudo nvidia-ctk runtime configure --runtime=podman
    sudo systemctl restart podman
    ```
  - Tester lâ€™accÃ¨s au GPU dans un conteneur :
    ```bash
    podman run --rm --device=nvidia.com/gpu=all nvcr.io/nvidia/cuda:12.4.1-base-ubuntu22.04 nvidia-smi
    ```
  - *Questions* :
    - Quel est le rÃ©sultat de cette commande ? (Doit afficher les infos de la GTX 3070.)
    - Si Ã§a ne marche pas, quelles erreurs obtients-tu ?
### 1.7 Le cas SELINUX

Pour Configurer SELinux avec Podman

1. VÃ©rifier l'Ã©tat global de SELinux
```bash
sestatus
```
=> VÃ©rifie que SELinux est en mode enforcing et que la politique targeted est active.

1. Configurer les BoolÃ©ens SELinux pour Podman
Ces commandes autorisent Podman Ã  gÃ©rer les ressources systÃ¨me nÃ©cessaires (cgroups, pÃ©riphÃ©riques, etc.) :
```bash
sudo setsebool -P container_manage_cgroup true   # Permet Ã  Podman de gÃ©rer les cgroups
sudo setsebool -P container_use_devices true     # Permet l'accÃ¨s aux pÃ©riphÃ©riques (ex: GPU)
```

2. Appliquer le Contexte SELinux aux Fichiers
Pour que Podman puisse lire/Ã©crire dans /mnt/podman :
```bash
# Appliquer le contexte temporairement
sudo chcon -R -t container_file_t /mnt/podman

# Rendre le changement permanent
sudo semanage fcontext -a -t container_file_t "/mnt/podman(/.*)?"

# Appliquer les rÃ¨gles SELinux (charge les changements)
sudo restorecon -Rv /mnt/podman
```
3. VÃ©rifications

a) VÃ©rifier les contextes des fichiers

```bash
ls -Z /mnt/podman
```
=> Tous les fichiers doivent afficher container_file_t (ex: drwxr-xr-x. dcrazyboy dcrazyboy system_u:object_r:container_file_t:s0).

b) VÃ©rifier les contextes des fichiers
```bash
podman run --rm -it -v /mnt/podman/shared_volumes:/test alpine ls /test
```
=> Si la commande liste le contenu de /test, SELinux est bien configurÃ©.

c) DÃ©boguer en cas d'erreur

Si la commande Ã©choue :
```bash
# Voir les refus d'accÃ¨s rÃ©cents
sudo ausearch -m avc -ts recent

# Voir les logs SELinux dans le noyau
sudo dmesg | grep -i selinux

# Alternative (si setroubleshoot est installÃ©)
sudo journalctl -t setroubleshoot
```
=> Ces commandes t'aident Ã  identifier quel contexte ou boolÃ©en manque.

4. Bonus : DÃ©sactiver SELinux Temporairement (pour tests)
Si tu veux vÃ©rifier si SELinux est bien le problÃ¨me :
```bash
# DÃ©sactiver SELinux (mode permissif)
sudo setenforce 0

# RÃ©activer SELinux (mode enforcing)
sudo setenforce 1
```
=> Ã€ utiliser uniquement pour le dÃ©bogage ! Ne laisse pas SELinux en mode permissif en production.

5. Eventuellement crÃ©er une policy particuliere
Si les rÃ¨gles par dÃ©faut ne suffisent pas, crÃ©e une politique personnalisÃ©e :

```bash
sudo audit2allow -a -M mypodman
sudo semodule -i mypodman.pp
```
6. RÃ©sumÃ©

|Commande|Description|
| :----- | :----- |
|sestatus|VÃ©rifier l'Ã©tat de SELinux.|
|chcon -t container_file_t /chemin|Changer le contexte d'un fichier.|
|semanage fcontext -a -t container_file_t "/chemin(/.*)?"|Rendre le changement permanent.|
|restorecon -Rv /chemin|Appliquer les rÃ¨gles SELinux.|
|setsebool -P container_manage_cgroup true|Autoriser Podman Ã  gÃ©rer les cgroups.|
|ls -Z /chemin|Voir les contextes SE|

### 1.8 le cas nvidia
1. Configuration des Modules NVIDIA


VÃ©rification des modules NVIDIA chargÃ©s :
```bash
lsmod | grep nvidia
```

CrÃ©ation des fichiers /dev/nvidia* avec les bonnes permissions :

CrÃ©ation manuelle de /dev/nvidia-uvm :
```bash
sudo mknod -m 666 /dev/nvidia-uvm c 195 254
```



2. Configuration des rÃ¨gles udev pour la persistance :


CrÃ©ation des fichiers de rÃ¨gles udev :
```bash
sudo nano /etc/udev/rules.d/70-nvidia-uvm.rules
```
Ajouter :
```bash
KERNEL=="nvidia-uvm", MODE="0666"
```

Configuration des permissions pour tous les fichiers NVIDIA :
```bash
sudo nano /etc/udev/rules.d/70-nvidia-permissions.rules
```
Ajouter :
```bash
KERNEL=="nvidia*", MODE="0666"
```



Rechargement des rÃ¨gles udev :
```bash
sudo udevadm control --reload-rules
sudo udevadm trigger
```


3. Configuration de nvidia-container-toolkit


RÃ©installation de nvidia-container-toolkit :
```bash
sudo zypper remove nvidia-container-toolkit
sudo zypper install nvidia-container-toolkit
```

GÃ©nÃ©ration du fichier de configuration CDI :
```bash
sudo nvidia-ctk cdi generate --output=/etc/cdi/nvidia.yaml
```

RedÃ©marrage de Podman :
```bash
systemctl --user restart podman.socket
```


4. VÃ©rification Finale


Test de l'accÃ¨s aux volumes partagÃ©s avec Podman :
```bash
podman run --rm -it -v /mnt/podman/shared_volumes:/test alpine ls /test
```

Test de l'accÃ¨s au GPU avec Podman :
```bash
podman run --rm --gpus all nvidia/cuda:12.4.0-runtime-ubuntu22.04 nvidia-smi
```


5. Persistance aprÃ¨s RedÃ©marrage


VÃ©rification des modules NVIDIA aprÃ¨s redÃ©marrage :
```bash
lsmod | grep nvidia
```

VÃ©rification des fichiers /dev/nvidia* aprÃ¨s redÃ©marrage :
```bash
ls -l /dev/nvidia*
```

---


## 2. Configuration/installation Technique

## 2.1 Installaiton / paramÃ¨trage Podman

ATTTENTION on est en rootless

### 2.1.1 Installation
```bash
sudo zypper install podman
#ajout du repos de nvidia-container-toolkit
sudo zypper ar -f https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
sudo zypper intall nvidia-container-toolkit

# vÃ©rifier la version
nvidia-ctk --version
NVIDIA Container Toolkit CLI version 1.17.8
commit: f202b80a9b9d0db00d9b1d73c0128c8962c55f4d

# gÃ©nÃ©rer le cdi

sudo nvidia-ctk cdi generate --output=/etc/cdi/nvidia.yaml


```
### 2.1.2 Configuration en mode rootless

```bash
# crÃ©e l'environement de stockage local d ela config
mkdir -p ~/.config/containers/oci/hooks.d/

# Configurer le hook NVIDIA

tee ~/.config/containers/oci/hooks.d/oci-nvidia-hook.json << 'EOF'
{
  "version": "1.0.0",
  "hook": {
    "createRuntime": {
      "path": "/usr/bin/nvidia-container-cli",
      "args": ["hook", "prestart"],
      "env": [
        "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
      ]
    }
  },
  "when": {
    "always": true,
    "commands": ["create", "start"]
  },
  "stages": ["prestart"]
}
EOF

# configurer policy.json
tee ~/.config/containers/policy.json << 'EOF'
{
  "default": [
    {
      "type": "insecureAcceptAnything"
    }
  ]
}
EOF

# configurer registriess.conf

tee ~/.config/containers/registries.conf << 'EOF'
unqualified-search-registries = ["docker.io", "ghcr.io", "quay.io"]
EOF

# genere container.conf (optionnel si problÃ¨me)

tee ~/.config/containers/containers.conf << 'EOF'
[containers]
default_ulimits = ["nofile=65535:65535", "memlock=-1:-1"]
runtime = "crun"
hooks_dir = ["~/.config/containers/oci/hooks.d/"]

EOF
# lancer poodman en rootless

systemctl --user start podman.socket

```

### 2.1.3 VÃ©rification et tests

```
tree ~/.config/containers/

/home/dcrazyboy/.config/containers/
â”œâ”€â”€ oci
â”‚Â Â  â””â”€â”€ hooks.d
â”‚Â Â      â””â”€â”€ oci-nvidia-hook.json
â”œâ”€â”€ policy.json
â””â”€â”€ registries.conf


 systemctl --user status podman.socket

â— podman.socket - Podman API Socket
     Loaded: loaded (/usr/lib/systemd/user/podman.socket; enabled; preset: disa>
     Active: active (listening) since Mon 2025-09-29 00:01:18 CEST; 6s ago
 Invocation: 30178af9513b4064844f7d96fe881cc1
   Triggers: â— podman.service
       Docs: man:podman-system-service(1)
     Listen: /run/user/1001/podman/podman.sock (Stream)
     CGroup: /user.slice/user-1001.slice/user@1001.service/app.slice/podman.soc>

sept. 29 00:01:18 pc-pro systemd[1739]: Listening on Podman API Socket.
```
Test avec image simple

```
podman pull docker.io/library/hello-world
Trying to pull docker.io/library/hello-world:latest...
Getting image source signatures
Copying blob 17eec7bbc9d7 done   | 
Copying config 1b44b5a3e0 done   | 
Writing manifest to image destination
1b44b5a3e06a9aae883e7bf25e45c100be0bb81a0e01b32de604f3ac44711634

```

Test de CUDA
```
podman pull docker.io/nvidia/cuda:12.4.0-runtime-ubuntu22.04
Trying to pull docker.io/nvidia/cuda:12.4.0-runtime-ubuntu22.04...
Getting image source signatures
Copying blob 42896cdfd7b6 done   | 
Copying blob bccd10f490ab done   | 
Copying blob e06eb1b5c4cc done   | 
Copying blob edd1dba56169 done   | 
Copying blob 7f308a765276 done   | 
Copying blob 3af11d09e9cd done   | 
Copying blob 600519079558 done   | 
Copying blob 0ae42424cadf done   | 
Copying blob 73b7968785dc done   | 
Copying config ea6fb18ed8 done   | 
Writing manifest to image destination
ea6fb18ed8621f89d4a193c33126be30a3f01557d3324967cd35cfb199c0f9ee
dcrazyboy@pc-pro:~> podman run --rm --security-opt label=disable --gpus all docker.io/nvidia/cuda:12.4.0-runtime-ubuntu22.04 nvidia-smi

==========
== CUDA ==
==========

CUDA Version 12.4.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.

Sun Sep 28 23:01:35 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 3070 ...    On  |   00000000:01:00.0 Off |                  N/A |
| N/A   39C    P0             29W /  130W |      15MiB /   8192MiB |      7%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
```

### 2.2 PrÃ©paration du Disque Externe
#### 2.2.2 **Ã‰tapes pour Configurer le Point de Montage**
1. **CrÃ©er un point de montage fixe** :
   ```bash
   sudo mkdir -p /mnt/podman
   ```
2. **Ajouter une entrÃ©e dans /etc/fstab** :
  Ã‰dite /etc/fstab avec sudo nano /etc/fstab et ajoute :
  ```bash
    UUID=83b38d7e-e781-497d-82e4-cffd5d35f582  /mnt/podman  ext4  defaults  0  2
  ```
  Explications :
    **uid=dcrazyboy,gid=dcrazyboy** : Donne les permissions Ã  ton utilisateur.
    **dmask=022,fmask=133** : Permet Ã  ton utilisateur de lire/Ã©crire les fichiers/dossiers.
    **nofail** : EmpÃªche les erreurs au dÃ©marrage si le disque nâ€™est pas branchÃ©.

2. **Monter le disque manuellement (pour tester)** :
  ```bash
  sudo mount /mnt/podman
  ```
3. **VÃ©rifier le montage** :
  ```bash
    ls /mnt/podman
  ```
  â†’ Doit afficher le contenu de ton disque.
4. **Permissions**
   DÃ©finir les permissions :
  ```bash
    sudo chcon -R -t container_file_t /mnt/podman
    sudo semanage fcontext -a -t container_file_t "/mnt/podman(/.*)?"
    sudo chown -R dcrazyboy\:dcrazyboy /mnt/podman
    sudo chmod -R 755 /mnt/podman
  ```
5. **CrÃ©er la structure sur le disque**
```bash
mkdir -p /mnt/podman/shared_volumes/images
mkdir -p /mnt/podman/shared_volumes/models
mkdir -p /mnt/podman/shared_volumes/workflows

```
6. **DÃ©placer les donnÃ©es existantes (si nÃ©cessaire)**
  ```bash
  mv ~/.local/share/containers/storage/* /mnt/podman/podman_data/storage/
  ```
7. **CrÃ©er le lien symbolique (si necessaire voir script plus loin)**
  ```bash
  ln -s /mnt/podman/podman_data/storage ~/.local/share/containers/storage
  ```
8. **Scripts de Montage/DÃ©montage**
**Fichier `mount_podman.sh`** :
```ini
#!/bin/bash

# Monter le disque
#pod_list=("pod_sd" "pod_comfyui" "pod_cdrage" "pod_kohya_ss" "pod_jupyter_lab" "build")
nb_ln=0
nb_ln_err=0
element=0
#Check que le disque exter est present
if ! mountpoint -q /mnt/podman; then
    sudo mount /mnt/podman
fi

if mountpoint -q /mnt/podman; then
    # Montage des pods
    for element in "${pod_list[@]}"; do
        # DÃ©finir le chemin de stockage personnalisÃ© pour ce pod
        CONFIG_FILE=~/.config/containers/storage-$element.conf

        # CrÃ©er le fichier de configuration pour Podman (une seule fois)
        if [ ! -f "$CONFIG_FILE" ]; then
            echo "ğŸ± CrÃ©ation du fichier de configuration pour $element..."
            mkdir -p ~/.config/containers/
            cat > "$CONFIG_FILE" <<EOF
[storage]
driver = "overlay"
graphroot = "/home/dcrazyboy/.local/share/$element/containers/storage"
runroot = "/run/user/$(id -u)"
EOF
        fi
        # CrÃ©er le dossier local s'il n'existe pas
        if [ ! -d ~/.local/share/"$element"/containers ]; then
            echo "ğŸ± CrÃ©ation du dossier local pour $element"
            mkdir -p ~/.local/share/"$element"/containers
        fi

        # CrÃ©er le dossier sur le disque externe s'il n'existe pas
        if [ ! -d /mnt/podman/"$element"/storage ]; then
            echo "ğŸ± CrÃ©ation du dossier externe pour $element"
            mkdir -p /mnt/podman/"$element"/storage
        fi

        # Supprimer le lien symbolique existant s'il y en a un
        if [ -e ~/.local/share/"$element"/containers/storage ]; then
            rm -rf ~/.local/share/"$element"/containers/storage
        fi

        # CrÃ©er le dossier local temporaire s'il n'existe pas
        if [ ! -d /mnt/podman/build/"$element" ]; then
            echo "ğŸ± CrÃ©ation du dossier temporaire pour $element"
            mkdir -p /mnt/podman/build/"$element"
        fi

        # CrÃ©er le lien symbolique
        ln -s /mnt/podman/"$element"/storage ~/.local/share/"$element"/containers
        echo "ğŸ± Lien symbolique pour $element crÃ©Ã©"
        nb_ln=$((nb_ln+1))
    done

    # check podman est actif
    if ! $(systemctl --user is-active podman.socket); then
        systemctl --user start podman.socket
    fi
    echo "ğŸ± Nombre de pods accessibles : $nb_ln | En erreur : $nb_ln_err"
else
    echo "âŒ Erreur : Le disque n'a pas pu Ãªtre montÃ©."
    exit 1
fi
```
**Fichier `env_podman.sh`** :
ce fichier initialise les variable systeme pour le pod avec lequel on veut travailler
```ini
#!/bin/bash

# Sourcer le script de montage (avec vÃ©rification)
MOUNT_SCRIPT="~/scripts/mount_podman.sh"
if [ -f "$MOUNT_SCRIPT" ]; then
    echo "ğŸ± VÃ©rification du montage des pods..."
    source "$MOUNT_SCRIPT"
else
    echo "âŒ Erreur : Le script $MOUNT_SCRIPT est introuvable."
    exit 1
fi

# Liste des pods valides
valid_pods=("pod_sd" "pod_comfyui" "pod_cdrage" "pod_kohya_ss" "pod_jupyter_lab")

# VÃ©rifier si l'argument est valide
if [[ ! " ${valid_pods[@]} " =~ " $1 " ]]; then
    echo "Pod inconnu. Pods valides :"
    printf '%s\n' "${valid_pods[@]}"
    exit 1
fi

# DÃ©finir les variables d'environnement
export CONTAINERS_STORAGE_CONF=~/.config/containers/storage-${1}.conf
export TMPDIR=/mnt/podman/build/${1}

# Afficher la configuration
echo "Configuration appliquÃ©e :"
echo "  - CONTAINERS_STORAGE_CONF = $CONTAINERS_STORAGE_CONF"
echo "  - TMPDIR = $TMPDIR"
```
**Fichier `env_build.sh`** :
ce fichier initialise les variable systeme pour le pod avec lequel on veut travailler
```ini
#!/bin/bash

# Sourcer le script de montage (avec vÃ©rification)
MOUNT_SCRIPT="~/scripts/mount_podman.sh"
if [ -f "$MOUNT_SCRIPT" ]; then
    echo "ğŸ± VÃ©rification du montage des pods..."
    source "$MOUNT_SCRIPT"
else
    echo "âŒ Erreur : Le script $MOUNT_SCRIPT est introuvable."
    exit 1
fi

# Liste des pods valides
valid_pods=("pod_sd" "pod_comfyui" "pod_cdrage" "pod_kohya_ss" "pod_jupyter_lab")

# VÃ©rifier si l'argument est valide
if [[ ! " ${valid_pods[@]} " =~ " $1 " ]]; then
    echo "Pod inconnu. Pods valides :"
    printf '%s\n' "${valid_pods[@]}"
    exit 1
fi

# DÃ©finir les variables d'environnement
export CONTAINERS_STORAGE_CONF=~/.config/containers/storage-${1}.conf
export TMPDIR=/mnt/podman/build/${1}
export PODMAN_STORAGE=/mnt/podman/build/storage

# Afficher la configuration
echo "Configuration appliquÃ©e :"
echo "  - CONTAINERS_STORAGE_CONF = $CONTAINERS_STORAGE_CONF"
echo "  - TMPDIR = $TMPDIR"
echo "  - PODMAN_STORAGE = $PODMAN_STORAGE"
```
utilisation :
ATTENTION bien faire source et pas ./ pour que les variables soient bien initialisÃ©es dans la session
```bash
source env_podman.sh <nom_du_pod>
#ou
source env_build.sh <nom_du_pod>

```

**Fichier `umount_podman.sh`** :
```ini
#!/bin/bash

# Monter le disque
pod_list=("pod_sd" "pod_comfyui" "pod_cdrage" "pod_kohya_ss" "pod_jupyter_lab" "build")
for element in "${pod_list[@]}"; do
  # Supprimer le lien symbolique jupyter_lab
  echo "Supprimer le lien symbolique ${element}"
  rm -rf ~/.local/share/${element}/containers/storage
done
# DÃ©monter le disque
sudo umount /mnt/podman
echo "ğŸ¾ Disque dÃ©montÃ© en sÃ©curitÃ© !"

```

Rendre les scripts exÃ©cutables :
```bash
chmod +x mount_podman.sh umount_podman.sh env_podman.sh env_build.sh
```

### 2.2.1 Dossiers PartagÃ©s (shared_volumes/)
- Objectif : Centraliser les images gÃ©nÃ©rÃ©es, modÃ¨les et workflows pour les partager entre pods (ex : SD â†’ ComfyUI).
  
  Exemple : 

  - Stable Diffusion sauvegarde ses outputs dans shared_volumes/images/stable-diffusion/.
  - ComfyUI peut lire ces images pour des opÃ©rations img2img en montant ce dossier.

Montage dans les Pods :
```bash
# Exemple pour Stable Diffusion
podman run -d \
  --name sd-pod \
  -v /mnt/podman/shared_volumes/images/stable-diffusion:/app/outputs \
  -v /mnt/podman/shared_volumes/models:/app/models \
  nvcr.io/nvidia/cuda:12.4.0

# Exemple pour ComfyUI (accÃ¨s aux images de SD)
podman run -d \
  --name comfyui-pod \
  -v /mnt/podman_external/shared_volumes/images:/app/images \
  comfyui/comfyui\:latest
```
### 2.2.2 Organisation :

Les logs restent dÃ©centralisÃ©s (dans chaque pod ou conteneur).
Les donnÃ©es partagÃ©es (images, modÃ¨les) sont centralisÃ©es dans shared_volumes/.

### 2.2.3 Permissions et Bonnes Pratiques

- Permissions :
  ```bash
  sudo chown -R \$USER:\$USER /mnt/podmanl
  ```
- DÃ©montage :
  Toujours arrÃªter les pods avant de dÃ©monter le disque.

### 2.2.4 Exemple de Workflow : SD â†’ ComfyUI

Stable Diffusion gÃ©nÃ¨re des images dans shared_volumes/images/stable-diffusion/.
ComfyUI monte shared_volumes/images/ et utilise les images de SD pour du img2img.
RÃ©sultat : Pas de duplication, flux de travail fluide.

### 2.2.5 Notes Importantes
#### 2.2.5.1 CompatibilitÃ© :
TestÃ© avec Podman en mode rootless.
Les chemins sont relatifs au point de montage (/mnt/podman/).
#### 2.2.5.2 Sauvegardes :
Sauvegardez rÃ©guliÃ¨rement podman_data/ et shared_volumes/ sur un autre support.


## 2.3 Vademecum Podman
### 2.3.1 Gestion courrante et bonne pratique

a. Gestion des Conteneurs
- Nommage des conteneurs : Utilise des noms explicites pour tes conteneurs afin de les identifier facilement.
```
podman run --name pod_<mon_conteneur> ...
```

- Utilisation des Pods : Si tu utilises plusieurs services liÃ©s (ex: Stable Diffusion + une base de donnÃ©es), regroupe-les dans un pod pour une gestion simplifiÃ©e.
```
podman pod create --name pod_<mon_pod>
podman run --pod pod_<mon_pod> --name nom_pod>_<appli> ...
```
- Persistance des donnÃ©es : Utilise des volumes pour les donnÃ©es persistantes (comme tu lâ€™as dÃ©jÃ  configurÃ© avec ton disque externe).
```
podman volume create <nom_pod>_data
podman run --mount type=volume,source=sd_data,target=/app/data ...
```

b. Gestion des Images

- Nettoyage rÃ©gulier : Supprime les images inutilisÃ©es pour libÃ©rer de lâ€™espace.
```
podman image prune
```
- Mise Ã  jour des images : Mets Ã  jour tes images rÃ©guliÃ¨rement pour bÃ©nÃ©ficier des derniÃ¨res corrections de sÃ©curitÃ©.
```
podman pull docker.io/nvidia/cuda:12.4.0-runtime-ubuntu22.04
```

c. Utilisation des Ressources

- Limitation des ressources : Utilise des limites de CPU et de mÃ©moire pour Ã©viter quâ€™un conteneur ne monopolise les ressources.
```
podman run --cpus=2 --memory=4g ...
```
2. Voir Ce Qui TraÃ®ne ou Tourne en TÃ¢che de Fond
  a. Lister les Conteneurs en Cours dâ€™ExÃ©cution
```
podman ps
```

(Affiche les conteneurs en cours dâ€™exÃ©cution.)

  b. Lister Tous les Conteneurs (y compris ceux arrÃªtÃ©s)
```
podman ps -a
```
(Affiche tous les conteneurs, y compris ceux qui sont arrÃªtÃ©s.)

  c. Lister les Pods

```
podman pod ps
```
(Affiche les pods en cours dâ€™exÃ©cution.)
  
  d. Voir les Ressources UtilisÃ©es par les Conteneurs
```
podman stats
```
(Affiche en temps rÃ©el lâ€™utilisation des ressources par les conteneurs.)

3. Nettoyage des Conteneurs et Pods InutilisÃ©s
a. ArrÃªter un Conteneur
```
podman stop nom_du_conteneur
```
b. Supprimer un Conteneur
```
podman rm nom_du_conteneur
```
c. Supprimer un Pod
```
podman pod rm nom_du_pod
```
d. Nettoyer les Conteneurs, Pods et RÃ©seaux InutilisÃ©s
```
podman system prune
```
(Supprime tous les conteneurs, pods et rÃ©seaux arrÃªtÃ©s, ainsi que les images non utilisÃ©es.)
e. Nettoyer les Volumes InutilisÃ©s
```
podman volume prune
```
(Supprime les volumes non utilisÃ©s.)

4. Exemple de Workflow pour Stable Diffusion (SD)
a.  CrÃ©er et DÃ©marrer un Pod pour SD
```
podman pod create --name sd_pod -p 7860:7860
podman run -dt --pod sd_pod --name sd_app \
  --security-opt label=disable --gpus all \
  -v /mnt/podman/pod_sd/storage:/app/storage \
  docker.io/nvidia/cuda:12.4.0-runtime-ubuntu22.04
```
b.  ArrÃªter et Nettoyer le Pod SD
```
podman pod stop sd_pod
podman pod rm sd_pod
```

5. ResumÃ©
   
| Action | Commande |
| :--- | :--- |
|Lister les conteneurs|podman ps -a|
|Lister les pods|podman pod ps -a|
|Voir les ressources|podman stats|
|ArrÃªter un conteneur|podman stop nom_du_conteneur|
|Supprimer un conteneur|podman rm nom_du_conteneur|
|Nettoyer le systÃ¨me|podman system prune|
|Nettoyer les volumes|podman volume prune|

### 2.3.2  Exemple de gestion automatique
Voici comment automatiser la gestion des pods et conteneurs pour Stable Diffusion (SD) avec des scripts. On va crÃ©er des scripts pour :

- DÃ©marrer un pod et ses conteneurs.
- ArrÃªter proprement le pod et ses conteneurs.
- Nettoyer les ressources inutilisÃ©es.


#### 2.3.2.1 Script pour DÃ©marrer un Pod de test et ses Conteneurs (SD)
##### 2.3.2.1.i avec interface web
Ce script crÃ©e un pod pour SD, ajoute un conteneur avec les ressources GPU, et monte les volumes nÃ©cessaires ainsi que l'interface web.

**Fichier `test_start_jupyter_lab.sh`** :
```ini
#!/bin/bash
# DÃ©finir le fichier de configuration pour ce pod
export CONTAINERS_STORAGE_CONF=~/.config/containers/storage-pod_jupyter_lab.conf
# Nom du pod et du conteneur
POD_NAME="pod_jupyter_lab"
CONTAINER_NAME="app_jupyter_lab"
PORT=8888
WORK_DIR="/mnt/podman/shared_volumes/jupyter_lab"
USER_UID=$(id -u)
USER_GID=$(id -g)

# VÃ©rifier si le port est dÃ©jÃ  utilisÃ©
if ss -tulnp | grep -q ":${PORT} "; then
    echo "Erreur: Le port ${PORT} est dÃ©jÃ  utilisÃ©."
    exit 1
fi

# Supprimer le pod s'il existe dÃ©jÃ 
if podman pod exists $POD_NAME; then
    echo "Le pod $POD_NAME existe dÃ©jÃ . RedÃ©marrage..."
    podman pod stop $POD_NAME
    podman pod rm $POD_NAME
fi

# CrÃ©er le rÃ©pertoire de travail s'il n'existe pas
if [ ! -d "$WORK_DIR" ]; then
    echo "CrÃ©ation du rÃ©pertoire de travail $WORK_DIR"
    sudo mkdir -p "$WORK_DIR"
    sudo chown -R $USER_UID:$USER_GID "$WORK_DIR"
    sudo chmod -R 775 "$WORK_DIR"
fi

# CrÃ©er le pod avec le port dÃ©fini
echo "CrÃ©ation du pod $POD_NAME avec le port $PORT"
podman pod create --name $POD_NAME -p $PORT:8888 --userns=keep-id

# DÃ©marrer le conteneur Jupyter Lab avec les UID et GID de l'utilisateur et ajouter le groupe users
echo "Lancement du conteneur $CONTAINER_NAME"
podman run -dt --pod $POD_NAME --name $CONTAINER_NAME \
  -v "$WORK_DIR:/home/jovyan/work" \
  -u $USER_UID:$USER_GID \
  --group-add=users \
  docker.io/jupyter/base-notebook:latest

sleep 10

# Afficher les logs du conteneur pour obtenir l'URL d'accÃ¨s
#echo "Logs du conteneur :"
#podman logs $CONTAINER_NAME

# Afficher l'URL d'accÃ¨s
TOKEN=$(podman logs $CONTAINER_NAME 2>&1 | grep -oP 'http://127.0.0.1:8888/lab\?token=\K[^ ]+')

if [ -n "$TOKEN" ]; then
    echo "AccÃ¨de Ã  Jupyter Lab via l'URL suivante :"
    echo "http://127.0.0.1:${PORT}/lab?token=${TOKEN}"
else
    echo "Impossible de rÃ©cupÃ©rer le token d'accÃ¨s. VÃ©rifie les logs du conteneur."
fi
```
##### 2.3.2.1.3 Utilisation mode Batch (sans interface)

- Principe : ExÃ©cuter des commandes directement dans le conteneur via podman exec.
Exemple :
podman exec -it sd_app python3 /app/storage/generate_images.py --prompt "un chat en train de coder" --output /app/storage/output.png

- Cas d'usage : GÃ©nÃ©ration d'images en arriÃ¨re-plan, traitements automatisÃ©s.

##### 2.3.2.1.4 Utilisation mode Web (avec interface)

- Principe : Mapper un port (ex: 7860) et accÃ©der Ã  l'interface via http://localhost:7860.
Exemple de dÃ©marrage :
podman run -dt --pod sd_pod --name sd_web -p 7860:7860 docker.io/automatic1111/stable-diffusion-webui:latest

- AccÃ¨s : Ouvrir un navigateur Ã  l'adresse http://localhost:7860.

##### 2.3.2.1.4 Bonnes Pratiques
- Ports : Toujours mapper les ports (-p 7860:7860) pour l'interface web.
- Volumes : Monter les dossiers nÃ©cessaires (-v /mnt/podman/pod_sd/storage:/app/storage).
- GPU : Ajouter --gpus all pour les conteneurs nÃ©cessitant CUDA.


#### 2.3.2.2 Script pour ArrÃªter un Pod et ses Conteneurs
Ce script arrÃªte proprement le pod et ses conteneurs.
#!/bin/bash
**Fichier `test_stop_jupyter_lab.sh`** :
```ini
#!/bin/bash

# Nom du pod et du conteneur
POD_NAME="pod_jupyter_lab"
CONTAINER_NAME="app_jupyter_lab"

# VÃ©rifier si le pod existe
if ! podman pod exists $POD_NAME; then
    echo "âš ï¸ Le pod $POD_NAME n'existe pas."
    exit 1
fi

# Afficher les informations du pod avant l'arrÃªt
echo "Statut actuel du pod $POD_NAME :"
podman pod ps --format "table {{.Name}}\t{{.Status}}"

# ArrÃªter le conteneur principal proprement
echo "ArrÃªt du conteneur $CONTAINER_NAME..."
podman stop $CONTAINER_NAME

# Attendre que le conteneur ait bien le temps de s'arrÃªter
sleep 5

# VÃ©rifier l'Ã©tat du conteneur aprÃ¨s l'arrÃªt
CONTAINER_STATE=$(podman inspect $CONTAINER_NAME --format '{{.State.Status}}')
echo "Ã‰tat du conteneur aprÃ¨s arrÃªt : $CONTAINER_STATE"

if [ "$CONTAINER_STATE" != "exited" ]; then
    echo "âš ï¸ Erreur lors de l'arrÃªt du conteneur $CONTAINER_NAME. Ã‰tat actuel : $CONTAINER_STATE"
    exit 1
fi

# ArrÃªter le pod
echo "ArrÃªt du pod $POD_NAME..."
podman pod stop $POD_NAME

# Attendre que le pod ait bien le temps de s'arrÃªter
sleep 5

# VÃ©rifier l'Ã©tat du pod aprÃ¨s l'arrÃªt
POD_STATE=$(podman pod inspect $POD_NAME --format '{{.State}}')
echo "Ã‰tat du pod aprÃ¨s arrÃªt : $POD_STATE"


if [[ "$POD_STATE" != "Stopped" && "$POD_STATE" != "Exited" ]]; then
    echo "âš ï¸ Erreur lors de l'arrÃªt du pod $POD_NAME. Ã‰tat actuel : $POD_STATE"
    exit 1
fi

# Supprimer le pod
echo "Suppression du pod $POD_NAME..."
podman pod rm $POD_NAME

echo "ğŸ¾ Pod $POD_NAME supprimÃ© avec succÃ¨s !"

# VÃ©rifier si le port est toujours utilisÃ©
if ss -tulnp | grep -q ":${PORT} "; then
    echo "âš ï¸ Le port ${PORT} est toujours utilisÃ© aprÃ¨s la suppression du pod."

    # Trouver et afficher le processus utilisant le port
    PID=$(sudo lsof -t -i :${PORT})
    if [ -n "$PID" ]; then
        echo "Processus utilisant le port ${PORT} : PID ${PID}"
    else
        echo "Aucun processus identifiable n'utilise le port ${PORT}."
    fi
else
    echo "ğŸ¾ Pod $POD_NAME supprimÃ© et port ${PORT} libÃ©rÃ© avec succÃ¨s !"
fi
```
#### 2.3.2.4  Script pour VÃ©rifier l'Ã‰tat des Pods et Conteneurs
Ce script affiche l'Ã©tat actuel des pods et conteneurs liÃ©s Ã  SD.
**Fichier `test_check_jupyter_lab.sh`** :
```ini
#!/bin/bash

# Nom du pod
POD_NAME="pod_jupyter_lab"

# Afficher l'Ã©tat du pod
echo "ğŸ± Ã‰tat du pod $POD_NAME :"
podman pod ps --filter name=$POD_NAME --format "table {{.Name}}\t{{.Status}}"

# Afficher les conteneurs du pod
echo -e "\nğŸ± Conteneurs dans le pod $POD_NAME :"
podman ps --pod --filter pod=$POD_NAME --format "table {{.Names}}\t{{.Status}}"

# Afficher les volumes utilisÃ©s
echo -e "\nğŸ± Volumes montÃ©s :"
podman volume ls --filter name=sd --format "table {{.Name}}\t{{.Driver}}"
```

#### 2.3.2.5 Explications et Bonnes Pratiques
a. Pourquoi Utiliser des Pods ?

- Isolation : Chaque pod est indÃ©pendant et peut Ãªtre gÃ©rÃ© sÃ©parÃ©ment.
- Partage de Ressources : Les conteneurs dans un pod partagent le mÃªme rÃ©seau et les mÃªmes volumes.
- FlexibilitÃ© : Tu peux ajouter ou supprimer des conteneurs dans un pod sans tout redÃ©marrer.

b. Bonnes Pratiques

- Nommage Clair : Utilise des noms explicites pour tes pods et conteneurs (ex: sd_pod, sd_app).
- Volumes PartagÃ©s : Utilise des volumes pour les donnÃ©es persistantes (ex: /mnt/podman/shared_volumes/models).
- Nettoyage RÃ©gulier : ExÃ©cute podman system prune rÃ©guliÃ¨rement pour libÃ©rer de lâ€™espace.


### 2.3.3 RÃ©solution des problÃ¨mes
#### 2.3.3.1 test 

a. creation
./test_start_jupyter_lab.sh 
e9b9752887f1bd5b21b2dde1e87002962f8a6bf33c11b0db3a4a67f9bed00623
Trying to pull docker.io/jupyter/base-notebook:latest...
Getting image source signatures
Copying blob 77e45ee945dc done   | 
Copying blob ef8373d600b0 done   | 
Copying blob aece8493d397 done   | 
Copying blob fd92c719666c done   | 
Copying blob 4f4fb700ef54 done   | 
Copying blob 088f11eb1e74 done   | 
Copying blob a30f89a0af6c done   | 
Copying blob dc42adc7eb73 done   | 
Copying blob 4f4fb700ef54 done   | 
Copying blob abaa8376a650 done   | 
Copying blob aa099bb9e49a done   | 
Copying blob 822c4cbcf6a6 done   | 
Copying blob 4f4fb700ef54 skipped: already exists  
Copying blob d25166dcdc7b done   | 
Copying blob 4f4fb700ef54 skipped: already exists  
Copying blob 964fc3e4ff9f done   | 
Copying blob 2c4c69587ee4 done   | 
Copying blob de2cdd875fa8 done   | 
Copying blob 75d33599f5f2 done   | 
Copying blob 4f4fb700ef54 skipped: already exists  
Copying config 07bb7d6acc done   | 
Writing manifest to image destination
3d03b85a7902e3e6cab30781a95a43d226afbb87c84dec12f23498a03f6caa78
ğŸ± Pod pod_jupyter_lab dÃ©marrÃ© avec succÃ¨s ! AccÃ¨de Ã  http://localhost:8888

b. check

---

### 2.4 Le build
Pour Ã©tudier et apprendre le cas de test est le suivaant : 

**IntÃ©gration de Stable Diffusion avec Podman et GPU**

#### **2.4.1. Objectifs**
- **Containeriser** une installation manuelle de Stable Diffusion (Automatic1111) avec Podman.
- **IntÃ©grer le GPU** via un conteneur CUDA dÃ©diÃ©.
- **GÃ©rer les volumes partagÃ©s** pour les modÃ¨les et les sorties.
- **Exposer l'interface web** (Gradio) avec un navigateur intÃ©grÃ© ou externe.

#### **2.4.2. Architecture Globale**

##### **a. Structure des RÃ©pertoires**
```
/mnt/podman/
â”œâ”€â”€ pod_sd/          # Lien symbolique vers ~/.local/share/containers/
â”‚   â””â”€â”€ storage/         # Contient images, conteneurs et mÃ©tadonnÃ©es Podman
â”‚       â”œâ”€â”€ libpod/      # DonnÃ©es internes (conteneurs, images, volumes)
â”‚       â”œâ”€â”€ overlay/      # Couches overlay
â”‚       â””â”€â”€ volumes/      # Volumes nommÃ©s (optionnel)
â”‚
/.../
â”œâ”€â”€ shared_volumes/      # Dossiers partagÃ©s entre pods (images, modÃ¨les, workflows)
â”‚   â”œâ”€â”€ images/          # Images gÃ©nÃ©rÃ©es par SD/ComfyUI/autres
â”‚   â”‚   â”œâ”€â”€ stable-diffusion/  # Outputs de Stable Diffusion
â”‚   â”‚   â”œâ”€â”€ comfyui/          # Outputs de ComfyUI
â”‚   â”‚   â””â”€â”€ ...              # Autres outils
â”‚   â”œâ”€â”€ models/          # ModÃ¨les partagÃ©s (checkpoints, LoRAs)
â”‚   â””â”€â”€ workflows/       # Workflows ComfyUI rÃ©utilisables
â”‚
â”œâ”€â”€ build/
â”‚   â”œâ”€â”€ storage/          # RÃ©pertoire pour stocker les images construites
â”‚   â”‚   â”œâ”€â”€ <nom_image_1> # RÃ©sultat du build
â”‚   â”‚   â”œâ”€â”€ <nom_image_2> # RÃ©sultat du build
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ pod_sd/           # RÃ©pertoire pour construire l'image de Stable Diffusion
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ scripts/
â”‚   â”œâ”€â”€ pod_base/         # RÃ©pertoire pour construire une image de base
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ scripts/
â”‚   â””â”€â”€ xxx/              # Autres projets
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â””â”€â”€ scripts/
â”‚
â””â”€â”€ README.md            # Instructions pour le montage et l'utilisation
```

##### **b. Composants**
| Composant | RÃ´le | Image/Technologie |
|-----------|------|-------------------|
| **Conteneur Stable Diffusion** | ExÃ©cute l'application et l'interface web | Image custom (basÃ©e sur `ubuntu:22.04`) |
| **Conteneur CUDA** | Fournit l'accÃ¨s au GPU | `nvidia/cuda:12.4.0-runtime-ubuntu22.04` |
| **Pod Podman** | Lie les conteneurs et gÃ¨re les volumes | Podman Pod |

---

#### **2.4.3. Variables d'Environnement**
Ajouter les variables suivantes Ã  `env_build.sh` :

```bash
# Chemins et ports
export SD_WEBUI_PORT=7860
export SD_MODELS_DIR=/models
export SD_OUTPUT_DIR=/output

# GPU et affichage
export CUDA_VISIBLE_DEVICES=0
export DISPLAY=:99  # Pour Xvfb (si navigateur intÃ©grÃ©)
```
#### **2.4.4. Dockerfile pour Stable Diffusion**
##### **a. Ã‰tapes ClÃ©s**

1. Base : ubuntu:22.04
2. Installer les dÃ©pendances :
   - Python, Git, wget, et outils systÃ¨me.
   - Navigateur (Firefox/Chrome) + Xvfb pour l'affichage.
3. Configurer l'environnement :

   - DÃ©finir les variables SD_MODELS_DIR, SD_OUTPUT_DIR, etc.
4. TÃ©lÃ©charger les modÃ¨les :
   - Cloner Automatic1111 et tÃ©lÃ©charger les modÃ¨les dans /models.
5. Exposer le port :
   - EXPOSE 7860 pour l'interface web.
##### **b. Exemple de Structure**
```
FROM ubuntu:22.04

# Installer les dÃ©pendances
RUN apt-get update && apt-get install -y \
    python3 python3-pip git wget firefox-esr xvfb \
    && rm -rf /var/lib/apt/lists/*

# Configurer l'environnement
ENV SD_WEBUI_PORT=7860
ENV SD_MODELS_DIR=/models
ENV SD_OUTPUT_DIR=/output

# Copier les scripts et tÃ©lÃ©charger les modÃ¨les
COPY env_build.sh /tmp/env_build.sh
RUN /tmp/env_build.sh && rm /tmp/env_build.sh

# Exposer le port
EXPOSE 7860

# Lancer l'application
CMD ["python3", "launch.py", "--listen", "--port=7860"]
```
#### **2.4.5. DÃ©ploiement avec Podman**
##### **a. CrÃ©er le Pod**
```bash
podman pod create --name sd-pod --share=ipc -p 7860:7860
```
##### **b. Ajouter le Conteneur CUDA**
```bash
podman run --pod sd-pod --gpus all -d --name cuda-container \
  nvidia/cuda:12.4.0-runtime-ubuntu22.04 sleep infinity
```
##### **c. Ajouter le Conteneur Stable Diffusion***
```bash
podman run --pod sd-pod -d --name sd-container \
  --volume=/mnt/podman/shared_volumes/models:/models \
  --volume=/mnt/podman/shared_volumes/images/stable-diffusion:/output \
  --volume=/usr/local/cuda:/usr/local/cuda\:ro \
  mon-image-stable-diffusion
```
#### **2.4.6. Scripts de Gestion**
##### **a. Script de Build**

RÃ´le : Builder l'image Stable Diffusion et la stocker dans /mnt/podman/build/storage/.

Exemple :
```bash
podman build -t mon-image-stable-diffusion -f /mnt/podman/build/pod_sd/Dockerfile
podman save mon-image-stable-diffusion -o /mnt/podman/build/storage/mon-image-stable-diffusion.tar
```

##### **b. Script de DÃ©ploiement**

RÃ´le : Charger l'image, crÃ©er le pod, et lancer les conteneurs.

Exemple :
```bash
podman load -i /mnt/podman/build/storage/mon-image-stable-diffusion.tar
# CrÃ©er le pod et lancer les conteneurs (voir section 2.4.5)
```

##### **c. Scripts Start/Stop**

Start :
```bash
podman pod start sd-pod
```
Stop :
```bash
podman pod stop sd-pod
```

#### **2.4.7. Points Ã  Valider**

- CompatibilitÃ© CUDA :

VÃ©rifier que nvidia/cuda:12.4.0-runtime-ubuntu22.04 est compatible avec le driver hÃ´te (13.0).


- Navigateur :

Tester l'affichage de l'interface web avec Xvfb ou exposer le port 7860 pour un navigateur externe.


- Permissions :

S'assurer que les volumes /models et /output ont les bonnes permissions (chmod -R 777).

#### **2.4.8. Plan d'Action**

1. Mettre Ã  jour env_build.sh avec les nouvelles variables.
2. RÃ©diger le Dockerfile pour Stable Diffusion.
3. Builder l'image et la stocker dans /mnt/podman/build/storage/.
4. CrÃ©er le pod et dÃ©ployer les conteneurs.
5. Tester :
   - AccÃ¨s Ã  l'interface web (http://localhost:7860).
   - GÃ©nÃ©ration d'images avec le GPU.
6. Automatiser les scripts de build, dÃ©ploiement, start/stop.

#### **2.4.8. IMPORTANT**
##### **2.4.8.1 Variable externes**
###### **a. Variables Existantes**

|Variable|RÃ´le|Exemple de valeur|
| :- | :- | :- |
|CONTAINERS_STORAGE_CONF|Chemin vers la configuration de stockage Podman|/mnt/podman/.config/containers/storage-${1}.conf|
|TMPDIR|RÃ©pertoire temporaire pour le build|/mnt/podman/build/${1}|
|PODMAN_STORAGE|RÃ©pertoire de stockage des images Podman|/mnt/podman/build/storage|
###### **b. Variables Ã  Ajouter**
|Variable|RÃ´le|Exemple de valeur|
| :- | :- | :- |
|SD_WEBUI_PORT|Port pour l'interface web de Stable Diffusion|7860
|SD_MODELS_DIR|RÃ©pertoire des modÃ¨les/models|/models
|SD_OUTPUT_DIR|RÃ©pertoire de sortie des images|/output|
|DISPLAY|Affichage X11 pour le navigateur (si nÃ©cessaire)|:99|
|CUDA_VISIBLE_DEVICES|GPU Ã  utiliser (si plusieurs)|0|

c. IntÃ©gration dans env_build.sh

Exemple :

##### **2.4.8.2 Structure des RÃ©pertoires et Volumes**
| Volume | Source (hote) | Destination (container) | Description |
| :- | :- | :- | :- |
|ModÃ¨les|/mnt/podman/shared_volumes/models|/models|ModÃ¨les Stable Diffusion|
|Sorties|/mnt/podman/shared_volumes/images/stable-diffusion|/output|Images gÃ©nÃ©rÃ©es|
|CUDAConteneur|cuda-container|/usr/local/cuda|BibliothÃ¨ques CUDA|

##### **2.4.8.3 Logique du Pod avec Navigateur IntÃ©grÃ©**
###### **a. Conteneurs**
| Conteneur | Image | Role | Volume |
| :- | :- | :- | :- |
|sd-container|Image buildÃ©e (Stable Diffusion + navigateur)|ExÃ©cute Stable Diffusion et l'interface web|/models, /output, /usr/local/|
|cuda|cuda-containernvidia/cuda:12.4.0-runtime-ubuntu22.04|Fournit CUDA|/usr/local/cuda|
###### **b. Commandes ThÃ©oriques**

- CrÃ©er le pod :
```bash
podman pod create --name sd-pod --share=ipc -p 7860:7860
```
- Ajouter le conteneur CUDA :
```bash
podman run --pod sd-pod --gpus all -d --name cuda-container nvidia/cuda:12.4.0-runtime-ubuntu22.04 sleep infinity
```
- Ajouter le conteneur Stable Diffusion :
```bash
podman run --pod sd-pod -d --name sd-container \
  --volume=/mnt/podman/shared_volumes/models:/models \
  --volume=/mnt/podman/shared_volumes/images/stable-diffusion:/output \
  --volume=/usr/local/cuda:/usr/local/cuda:ro \
  mon-image-stable-diffusion
```
##### **2.4.8 Evolution des scripts**
###### **a. env_build.sh**

Ce script mest en place els acces et les variables pour l'environnement de build
```bash
#!/bin/bash

# Sourcer le script de montage (avec vÃ©rification)
MOUNT_SCRIPT="$HOME/scripts/mount_podman.sh"
if [ -f "$MOUNT_SCRIPT" ]; then
    echo "ğŸ± VÃ©rification du montage des pods..."
    source "$MOUNT_SCRIPT" "build"
else
    echo "âŒ Erreur : Le script $MOUNT_SCRIPT est introuvable."
    exit 1
fi

# Liste des pods valides
valid_pods=("pod_sd" "pod_comfyui" "pod_cdrage" "pod_kohya_ss" "pod_jupyter_lab")

# VÃ©rifier si l'argument est valide
for element in "${pod_list[@]}"; do
  # ajoute les variables spÃ©cifique si besoin 
  if [[ ! " ${element}} " == "${1}" ]]; then
    case $element in
      pod_sd)
        export SD_WEBUI_PORT=7860
        export SD_MODELS_DIR=/mnt/podman/shared_volumes/models
        export SD_OUTPUT_DIR=/mnt/podman/shared_volumes/images/stable-diffusion
        export DISPLAY=:99
        export CUDA_VISIBLE_DEVICES=0
        echo "Configuration spÃ©cifique appliquÃ©e :"
        echo "  - SD_WEBUI_PORT = $SD_WEBUI_PORT"
        echo "  - SD_MODELS_DIR = $SD_MODELS_DIR"
        echo "  - SD_OUTPUT_DIR = $SD_OUTPUT_DIR"
        echo "  - DISPLAY = $DISPLAY"
        echo "  - CUDA_VISIBLE_DEVICES = $CUDA_VISIBLE_DEVICES"
        ;;
      pod_comfyui)
        ;;
      pod_cdrage)
        ;; 
      pod_kohya_ss)
        ;;
      pod_jupyter_lab)
        ;;
      *)
        echo "Pod inconnu."
        exit 1
        ;;
    esac
  fi
done

# DÃ©finir les variables d'environnement
export CONTAINERS_STORAGE_CONF=$HOME/.config/containers/storage-${1}.conf
export TMPDIR=/mnt/podman/build/${1}
export PODMAN_STORAGE=/mnt/podman/build/storage

# Afficher la configuration
echo "Configuration gÃ©nÃ©rale appliquÃ©e :"
echo "  - CONTAINERS_STORAGE_CONF = $CONTAINERS_STORAGE_CONF"
echo "  - TMPDIR = $TMPDIR"
echo "  - PODMAN_STORAGE = $PODMAN_STORAGE"

```

### Prerequis

## 3. Automatisation et Scripts
### 3.1. Pod de Base (CUDA 12.4)

**Objectif**
CrÃ©er un pod de base avec CUDA 12.4 pour tester lâ€™accÃ¨s au GPU et servir de base Ã  lâ€™installation de Stable Diffusion.

#### 3.1.1. Configuration du NVIDIA Container Toolkit pour Podman Rootless
VÃ©rification de lâ€™Installation
nvidia-ctk --version

â†’ Doit afficher une version rÃ©cente (ex : NVIDIA Container Toolkit CLI version 1.17.8).

**Configuration du Hook NVIDIA**

CrÃ©er le dossier de configuration :
```bash
mkdir -p ~/.config/containers/oci/hooks.d/
```
Ajouter le hook NVIDIA :
```bash
tee ~/.config/containers/oci/hooks.d/oci-nvidia-hook.json << 'EOF'
{
  "version": "1.0.0",
  "hook": {
    "createRuntime": {
      "path": "/usr/bin/nvidia-container-cli",
      "args": ["hook", "prestart"],
      "env": [
        "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
      ]
    }
  },
  "when": {
    "always": true,
    "commands": ["create", "start"]
  },
  "stages": ["prestart"]
}
EOF
```
RedÃ©marrer Podman :
```bash
systemctl --user restart podman.socket
```

VÃ©rification des PÃ©riphÃ©riques NVIDIA
```bash
ls -l /dev/nvidia*
```
â†’ Doit afficher les pÃ©riphÃ©riques /dev/nvidia0, /dev/nvidiactl, /dev/nvidia-uvm, etc.
```bash
ls -l /dev/nvidia*
crw-rw-rw-+ 1 root root 195,   0 26 oct.  23:56 /dev/nvidia0
crw-rw-rw-+ 1 root root 195, 255 26 oct.  23:56 /dev/nvidiactl
crw-rw-rw-+ 1 root root 195, 254 26 oct.  23:56 /dev/nvidia-modeset
crw-rw-rw-. 1 root root 510,   0 27 oct.  22:18 /dev/nvidia-uvm
crw-rw-rw-. 1 root root 510,   1 27 oct.  22:18 /dev/nvidia-uvm-tools

/dev/nvidia-caps:
total 0
cr--------. 1 root root 237, 1 27 oct.  22:18 nvidia-cap1
cr--r--r--. 1 root root 237, 2 27 oct.  22:18 nvidia-cap2
```


#### 3.1.1.2. si /dev/nvidia-uvm a une taille null

```bash
sudo rm /dev/nvidia-uvm
sudo mknod -m 666 /dev/nvidia-uvm c 195 254
s -l /dev/nvidia*
crw-rw-rw-+ 1 root root 195,   0 26 oct.  23:56 /dev/nvidia0
crw-rw-rw-+ 1 root root 195, 255 26 oct.  23:56 /dev/nvidiactl
crw-rw-rw-+ 1 root root 195, 254 26 oct.  23:56 /dev/nvidia-modeset
crw-rw-rw-. 1 root root 195, 254 27 oct.  22:31 /dev/nvidia-uvm
crw-rw-rw-. 1 root root 510,   1 27 oct.  22:18 /dev/nvidia-uvm-tools

/dev/nvidia-caps:
total 0
cr--------. 1 root root 237, 1 27 oct.  22:18 nvidia-cap1
cr--r--r--. 1 root root 237, 2 27 oct.  22:18 nvidia-cap2
```




3.1.2. Test du Pod de Base avec CUDA
Lancement dâ€™un Conteneur de Test
 

```bash
podman run --rm --gpus all nvcr.io/nvidia/pytorch:23.10-py3 nvidia-smi

=============
== PyTorch ==
=============

NVIDIA Release 23.10 (build 71422337)
PyTorch Version 2.1.0a0+32f93b1

Container image Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

Copyright (c) 2014-2023 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

ERROR: The NVIDIA Driver is present, but CUDA failed to initialize.  GPU functionality will not be available.
   [[ Unknown error (error 999) ]]

Mon Oct 27 21:34:22 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 3070 ...    Off |   00000000:01:00.0 Off |                  N/A |
| N/A   34C    P0             24W /  130W |      15MiB /   8192MiB |      7%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
```
puis 
```bash
podman run --rm --gpus all -it nvcr.io/nvidia/pytorch:23.10-py3 python3 -c "import torch; print(torch.__version__); print(torch.cuda.is_available())"

=============
== PyTorch ==
=============

NVIDIA Release 23.10 (build 71422337)
PyTorch Version 2.1.0a0+32f93b1

Container image Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

Copyright (c) 2014-2023 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

2.1.0a0+32f93b1
True
```

- **Script de crÃ©ation** (`create-base-pod.sh`) :
```bash
#!/bin/bash
POD_NAME="cuda-base"
IMAGE_NAME="nvcr.io/nvidia/cuda:12.4.1-runtime-ubuntu22.04"
EXTERNAL_STORAGE="/chemin/vers/disque/externe/podman/pods/\$POD_NAME"

mkdir -p "\$EXTERNAL_STORAGE"
podman pod create --name "\$POD_NAME" --device=nvidia.com/gpu=all
podman run -it --pod "\$POD_NAME" --mount type=bind,source="\$EXTERNAL_STORAGE",destination=/app/data "\$IMAGE_NAME" /bin/
```

### 3.2. Pods Applicatifs

#### 3.2.1 Jupyter_lab

Jupyter_lab a servi de base pour l'etablissement des scripts de base de la section 2
les script suivants on Ã©tÃ© duppliquer et validÃ©s car fonctionnel en section 2
test_start_jupyter_lab.sh => start_jupyter_lab.sh
test_stop_jupyter_lab.sh => stop_jupyter_lab.sh
test_check_jupyter_lab.sh => check_jupyter_lab.sh
 
#### 3.2.2 Stable_diffusion
##### 3.2.2.1 Choix

Explications des Choix
a. Mode Web par DÃ©faut

Le mode web est plus flexible et permet d'accÃ©der Ã  l'interface graphique de Stable Diffusion.
Tu peux toujours utiliser le conteneur en mode bash si nÃ©cessaire.

b. IntÃ©gration du GPU

--device=nvidia.com/gpu=all : Cette option permet au pod d'accÃ©der aux GPU NVIDIA, ce qui est essentiel pour Stable Diffusion.

b. Stockage Externe

EXTERNAL_STORAGE : Un rÃ©pertoire de stockage externe est crÃ©Ã© et montÃ© dans /app/data Ã  l'intÃ©rieur du conteneur. Cela permet de sauvegarder des donnÃ©es supplÃ©mentaires si nÃ©cessaire.

c. Port 7860

Le port 7860 est le port par dÃ©faut pour l'interface web de Stable Diffusion.

d. Montage des Volumes

d'apres l'aorbrescence prevue

â”œâ”€â”€ shared_volumes/      # Dossiers partagÃ©s entre pods (images, modÃ¨les, workflows)
â”‚   â”œâ”€â”€ images/          # Images gÃ©nÃ©rÃ©es par SD/ComfyUI/autres
â”‚   â”‚   â”œâ”€â”€ stable-diffusion/  # Outputs de Stable Diffusion
â”‚   â”‚   â”œâ”€â”€ comfyui/          # Outputs de ComfyUI
â”‚   â”‚   â””â”€â”€ ...              # Autres outils
â”‚   â”œâ”€â”€ models/          # ModÃ¨les partagÃ©s (checkpoints, LoRAs)
â”‚   â””â”€â”€ workflows/       # Workflows ComfyUI rÃ©utilisables

d.1 Montage des ModÃ¨les

â”œâ”€â”€ shared_volumes/      # Dossiers partagÃ©s entre pods (images, modÃ¨les, workflows)
â”‚   â”œâ”€â”€ models/          # ModÃ¨les partagÃ©s (checkpoints, LoRAs)

$WORK_DIR:/workspace/models : Les modÃ¨les (checkpoints, LoRAs) sont montÃ©s dans /workspace/models Ã  l'intÃ©rieur du conteneur.

d.2 Montage des Images GÃ©nÃ©rÃ©es

â”œâ”€â”€ shared_volumes/      # Dossiers partagÃ©s entre pods (images, modÃ¨les, workflows)
â”‚   â”œâ”€â”€ images/          # Images gÃ©nÃ©rÃ©es par SD/ComfyUI/autres
â”‚   â”‚   â”œâ”€â”€ stable-diffusion/  # Outputs de Stable Diffusion

$EXTERNAL_STORAGE:/workspace/images : Les images gÃ©nÃ©rÃ©es par Stable Diffusion sont montÃ©es dans /workspace/images Ã  l'intÃ©rieur du conteneur.

e. Variables USER_UID et USER_GID :

Ces variables permettent de rÃ©cupÃ©rer l'UID et le GID de l'utilisateur actuel pour les utiliser dans le conteneur.


f. Option -u $USER_UID:$USER_GID :

Cette option permet de lancer le conteneur avec les mÃªmes UID et GID que l'utilisateur actuel, ce qui Ã©vite les problÃ¨mes de permissions.

g. Option --group-add=users :

Ajoute le groupe users Ã  l'utilisateur dans le conteneur, ce qui permet d'accÃ©der aux fichiers avec les bonnes permissions.
Deux volumes sont montÃ©s :

##### 3.2.2.2 Utilisation mode Batch (sans interface)

- Principe : ExÃ©cuter des commandes directement dans le conteneur via podman exec.
Exemple :
podman exec -it sd_app python3 /app/storage/generate_images.py --prompt "un chat en train de coder" --output /app/storage/output.png

- Cas d'usage : GÃ©nÃ©ration d'images en arriÃ¨re-plan, traitements automatisÃ©s.

##### 3.2.2.3  Utilisation mode Web (avec interface)

- Principe : Mapper un port (ex: 7860) et accÃ©der Ã  l'interface via http://localhost:7860.
Exemple de dÃ©marrage :
podman run -dt --pod sd_pod --name sd_web -p 7860:7860 docker.io/automatic1111/stable-diffusion-webui:latest

- AccÃ¨s : Ouvrir un navigateur Ã  l'adresse http://localhost:7860.

##### 3.2.2.4 Script demarage avec interface web
Ce script crÃ©e un pod pour SD, ajoute un conteneur avec les ressources GPU, et monte les volumes nÃ©cessaires ainsi que l'interface web.

**Fichier `start_sd.sh`** :
```ini
#!/bin/bash
# DÃ©finir le fichier de configuration pour ce pod
export CONTAINERS_STORAGE_CONF=~/.config/containers/storage-pod_sd.conf
# Nom du pod et du conteneur
POD_NAME="pod_sd"
CONTAINER_NAME="app_sd"
WEB_CONTAINER_NAME="web_sd"
PORT=7860
WORK_DIR="/mnt/podman/shared_volumes/models"
EXTERNAL_STORAGE="/mnt/podman/shared_volumes/images/stable-diffusion"
USER_UID=$(id -u)
USER_GID=$(id -g)

# VÃ©rifier si le port est dÃ©jÃ  utilisÃ©
if ss -tulnp | grep -q ":${PORT} "; then
    echo "Erreur: Le port ${PORT} est dÃ©jÃ  utilisÃ©."
    exit 1
fi

# Supprimer le pod s'il existe dÃ©jÃ 
if podman pod exists $POD_NAME; then
    echo "Le pod $POD_NAME existe dÃ©jÃ . RedÃ©marrage..."
    podman pod stop $POD_NAME
    podman pod rm $POD_NAME
fi

# CrÃ©er le rÃ©pertoire de travail s'il n'existe pas
if [ ! -d "$WORK_DIR" ]; then
    echo "CrÃ©ation du rÃ©pertoire de travail $WORK_DIR"
    sudo mkdir -p "$WORK_DIR"
    sudo chown -R $USER_UID:$USER_GID "$WORK_DIR"
    sudo chmod -R 755 "$WORK_DIR"
fi

# CrÃ©er le rÃ©pertoire de stockage externe s'il n'existe pas
if [ ! -d "$EXTERNAL_STORAGE" ]; then
    echo "CrÃ©ation du rÃ©pertoire de stockage externe $EXTERNAL_STORAGE"
    sudo mkdir -p "$EXTERNAL_STORAGE"
    sudo chown -R $USER_UID:$USER_GID "$EXTERNAL_STORAGE"
    sudo chmod -R 755 "$EXTERNAL_STORAGE"
fi

# CrÃ©er le pod avec le port dÃ©fini et l'accÃ¨s au GPU
echo "CrÃ©ation du pod $POD_NAME avec le port $PORT et l'accÃ¨s au GPU"
podman pod create --name $POD_NAME -p $PORT:7860 --device=nvidia.com/gpu=all --device=/dev/nvidia-uvm --device=/dev/nvidia-uvm-tools --device=/dev/nvidiactl --userns=keep-id

# DÃ©marrer le conteneur Stable Diffusion en mode web avec les volumes montÃ©s
echo "Lancement du conteneur $CONTAINER_NAME en mode web"
podman run -dt --pod $POD_NAME --name $CONTAINER_NAME \
  -v "$WORK_DIR:/workspace/models:Z" \
  -v "$EXTERNAL_STORAGE:/workspace/images:Z" \
  -u $USER_UID:$USER_GID \
  --group-add=users \
  --workdir /workspace \
  docker.io/runpod/stable-diffusion:latest

# DÃ©marrer un conteneur avec un serveur web pour Stable Diffusion
echo "Lancement du conteneur $WEB_CONTAINER_NAME pour le serveur web"
podman run -dt --pod $POD_NAME --name $WEB_CONTAINER_NAME \
  -v "$WORK_DIR:/workspace/models:Z" \
  -v "$EXTERNAL_STORAGE:/workspace/images:Z" \
  -u $USER_UID:$USER_GID \
  --group-add=users \
  --workdir /workspace \
  docker.io/runpod/stable-diffusion:latest \
  /bin/bash -c "cd /workspace/stable-diffusion-webui && python3 launch.py --listen --xformers --enable-insecure-extension-access"

# Attendre quelques secondes pour que Stable Diffusion dÃ©marre
sleep 30

# Afficher les logs du conteneur web
echo "Logs du conteneur web :"
podman logs $WEB_CONTAINER_NAME

# Afficher l'URL d'accÃ¨s
echo "AccÃ¨de Ã  Stable Diffusion via l'URL suivante :"
echo "http://127.0.0.1:${PORT}"


podman pod create --name $POD_NAME -p $PORT:7860 --device=nvidia.com/gpu=all --device=/dev/nvidia-uvm --device=/dev/nvidia-uvm-tools --device=/dev/nvidiactl --userns=keep-id

```

##### 3.2.2.5 Script d'arret avec interface web
Ce script crÃ©e un pod pour SD, ajoute un conteneur avec les ressources GPU, et monte les volumes nÃ©cessaires ainsi que l'interface web.

**Fichier `stop_sd.sh`** :
```ini
#!/bin/bash

# Nom du pod et du conteneur
POD_NAME="pod_sd"
CONTAINER_NAME="app_sd"

# VÃ©rifier si le pod existe
if ! podman pod exists $POD_NAME; then
    echo "âš ï¸ Le pod $POD_NAME n'existe pas."
    exit 1
fi

# Afficher les informations du pod avant l'arrÃªt
echo "Statut actuel du pod $POD_NAME :"
podman pod ps --format "table {{.Name}}\t{{.Status}}"

# ArrÃªter le conteneur principal proprement
echo "ArrÃªt du conteneur $CONTAINER_NAME..."
podman stop $CONTAINER_NAME

# Attendre que le conteneur ait bien le temps de s'arrÃªter
sleep 2

# ArrÃªter le pod
echo "ArrÃªt du pod $POD_NAME..."
podman pod stop $POD_NAME

# Attendre que le pod ait bien le temps de s'arrÃªter
sleep 2

# Supprimer le pod
echo "Suppression du pod $POD_NAME..."
podman pod rm $POD_NAME

echo "ğŸ¾ Pod $POD_NAME supprimÃ© avec succÃ¨s !"

```

#### 3.3. Sauvegarde et PortabilitÃ©

Sauvegarder une image :
```bash
podman save -o /chemin/vers/disque/externe/podman/images/mon-image.tar mon-image
```

Recharger une image :
```bash
podman load -i /chemin/vers/disque/externe/podman/images/mon-image.tar
```
Limites :

Les pods ne sont pas exportables directement. Il faudra recrÃ©er les pods sur un autre systÃ¨me Ã  partir des images et des scripts.
---
### 4. Points Ouverts Ã  Approfondir
#### 4.1. CompatibilitÃ© des Applications

Stable Diffusion/ComfyUI :

Quelles versions veux-tu utiliser ? (ex : SD 1.5, SDXL, ComfyUI custom ?)
Ces versions ont-elles des exigences spÃ©cifiques (ex : CUDA 11.8) ?


Action : Lister les dÃ©pendances exactes pour chaque application.

#### 4.2. Gestion des DonnÃ©es

ModÃ¨les et Outputs :

OÃ¹ et comment stocker les gros fichiers (checkpoints, LORAs) ?
Comment les partager entre diffÃ©rents pods (si nÃ©cessaire) ?


Proposition :

Un dossier /podman/shared/models/ pour les modÃ¨les communs ?
Un dossier /podman/pods/<app>/outputs/ pour les rÃ©sultats ?



#### 4.3. Automatisation AvancÃ©e

Scripts vs Kubernetes :

Les scripts Bash suffisent pour lâ€™instant, mais si la complexitÃ© augmente, on peut envisager des fichiers YAML (compatible avec podman play kube).
Question : Veux-tu un exemple de fichier YAML pour un pod ?



#### 4.4. SÃ©curitÃ© et Permissions

Mode Rootless :

Podman en rootless a des limitations (ex : ports < 1024, certains devices).
Ã€ vÃ©rifier : As-tu besoin dâ€™accÃ¨s privilÃ©giÃ©s pour certaines applications ?

---

## 5. Ã‰tapes Suivantes ProposÃ©es et gestion du document

Valider lâ€™accÃ¨s GPU dans un conteneur Podman (cf. 1.2).
CrÃ©er le pod de base avec CUDA 12.4 et tester le montage du stockage externe.
Discuter de lâ€™organisation des donnÃ©es (modÃ¨les, outputs) et des dÃ©pendances Python.
Ã‰crire un script pour un pod applicatif (ex : Stable Diffusion).


Notes :

Ce document est Ã©volutif : ajoute tes questions, tes retours dâ€™expÃ©rience, ou tes ajustements.
Pour chaque point, on peut approfondir avec des exemples concrets ou des tests.

---

### Comment lâ€™utiliser ?
1. Copie ce contenu dans un fichier `rules-podman.md` sur ton PC.
2. Ajoute tes notes, questions ou modifications directement dans le fichier.
3. Quand tu veux approfondir un point, dis-moi lequel, et on avance Ã©tape par Ã©tape.

---
**Question pour toi** :
Par quel point veux-tu commencer ? Par exemple :
- Tester lâ€™accÃ¨s GPU dans un conteneur ?
- Discuter de lâ€™organisation des dossiers sur le disque externe ?
- Ã‰crire le script pour le pod de base ?

---
## **ğŸ”¹ Prochaines Ã‰tapes**
# âœ… PROCHAINES Ã‰TAPES
- [âœ…] Section1 : Contraintes et Choix de Base (validÃ©e)
  - [âœ…] Stockage sur Disque Externe Amovible
  - [âœ…] Rootless or not rootless
  - [âœ…] Choix de l'image utilisÃ©e (image personnalisÃ©e, Image de cdrage)
  - [âœ…] Rootless or not rootless
  - [âœ…] AccÃ©lÃ©ration GPU
  - [âœ…] Version de CUDA (FixÃ©e Ã  12.4)
  - [âœ…] Bypasse montage automatique ?
- [âœ…] Section 2 : Configuration/installation Technique (section 2)
  - [âœ…] Installation podman
    - [âœ…] Installation / demarrage (rootless)
    - [âœ…] Installation nvidia-container-toolkit
    - [âœ…] Test
  - [âœ…] Installation disque externe
    - [âœ…] CÃ©ration structure
    - [âœ…] Montage et scripte si non automatique
  - [âœ…] Vademecum podman
    - [âœ…] Gestion courrantes
    - [âœ…] resolution problÃ¨me
  - [ ] Le build
    - [ ] Mise en place environnement
    - [ ] Construction
    - [ ] Test
- [ ]Automatisation des pod prevu
  - [ ] Stable diffusion
    - [ ] scripts sopt/start mode web /bash
    - [ ] test
  - [ ] ComfyUI
    - [ ] scripts sopt/start mode web /bash
    - [ ] test
  - [ ] cdrage
    - [ ] scripts sopt/start mode web /bash
    - [ ] test
  - [ ] kohya_ss
    - [ ] scripts sopt/start mode web /bash
    - [ ] test
  - [âœ…] jupyter_lab
    - [âœ…] scripts sopt/start mode web /bash
    - [âœ…] test


